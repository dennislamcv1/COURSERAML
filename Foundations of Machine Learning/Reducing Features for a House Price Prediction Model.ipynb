{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2457e1b8",
   "metadata": {},
   "source": [
    "# üë©‚Äçüíª Feature Selection and Extraction for Housing Price Prediction\n",
    "## üìã Overview\n",
    "In this lab, you'll tackle a real-world machine learning challenge: reducing the number of features in the Ames Housing Dataset while maintaining or improving predictive performance. You'll implement feature selection using Recursive Feature Elimination (RFE) and dimensionality reduction using Principal Component Analysis (PCA), then compare their effectiveness for a linear regression model. These techniques are essential for any data scientist working with high-dimensional datasets as they help improve model efficiency, reduce overfitting, and increase interpretability.\n",
    "## üéØ Learning Outcomes\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "- Apply Recursive Feature Elimination to identify the most important features in a dataset\n",
    "- Implement Principal Component Analysis for dimensionality reduction\n",
    "- Compare and evaluate the performance of models using different feature selection techniques\n",
    "- Make informed decisions about feature selection trade-offs in real-world scenarios\n",
    "\n",
    "## üöÄ Starting Point\n",
    "Access the starter code provided below. You'll need a Python environment with the following libraries:\n",
    "\n",
    "- pandas\n",
    "- numpy\n",
    "- scikit-learn\n",
    "- matplotlib (optional, for visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb4dd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the Ames Housing dataset\n",
    "ames = fetch_openml(name=\"house_prices\", as_frame=True)\n",
    "data = ames.data\n",
    "data['SalePrice'] = ames.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76d13a7",
   "metadata": {},
   "source": [
    "## Task 1: Explore the Dataset\n",
    "**Context:** Before applying any feature selection technique, it's important to understand the dataset you're working with. Real estate analysts often start by exploring housing data to get a sense of the available features and their distributions.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Examine the first few rows of the dataset using the `head()` method\n",
    "2. Get statistical summaries of numerical features using `describe()`\n",
    "3. Check for missing values in the dataset using methods like `isna().sum()`\n",
    "4. Handle missing values in numerical features using appropriate strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1417ab5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the dataset\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Handle missing values\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Define features and target\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a1fbd8",
   "metadata": {},
   "source": [
    "**üí° Tip:** For simplicity in this lab, consider using only numerical features and handling missing values with median imputation.\n",
    "\n",
    "**‚öôÔ∏è Test Your Work:**\n",
    "\n",
    "- Print the shape of your processed dataset\n",
    "- Verify that there are no missing values in the data you'll use for modeling\n",
    "- Expected output: A confirmation of the dataset dimensions and features you'll be working with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97edd944",
   "metadata": {},
   "source": [
    "## Task 2: Apply Recursive Feature Elimination (RFE)\n",
    "**Context:** Real estate companies often want to know which housing attributes are most predictive of sales price. RFE helps identify the most important features while eliminating redundant or less important ones.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Create a Linear Regression model to use as the base estimator\n",
    "2. Initialize the RFE with the model, specifying to select the top 5 features\n",
    "3. Fit RFE to your data\n",
    "4. Extract and display the selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e99de78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Recursive Feature Elimination\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Extract selected features\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4315759",
   "metadata": {},
   "source": [
    "**üí° Tip:** The `RFE` class has a `support_` attribute that shows which features were selected. You can use this with your original feature names to identify the selected features.\n",
    "\n",
    "**‚öôÔ∏è Test Your Work:**\n",
    "\n",
    "- Print the names of the selected features\n",
    "- Expected output: A list of the 5 most important features for predicting house prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c452598",
   "metadata": {},
   "source": [
    "## Task 3: Implement Principal Component Analysis (PCA)\n",
    "**Context:** In many real-world datasets including real estate data, features may be correlated. PCA transforms the original features into uncorrelated principal components that capture the maximum variance in the data.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Standardize the features using `StandardScaler`\n",
    "2. Initialize PCA with 2 components to start\n",
    "3. Fit and transform the data using PCA\n",
    "4. Examine the explained variance ratio to understand how much information is retained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2571d325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Apply PCA\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Examine explained variance\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215f1e9e",
   "metadata": {},
   "source": [
    "**üí° Tip:** Always standardize your data before applying PCA since it is sensitive to the scale of the features.\n",
    "    \n",
    "**‚öôÔ∏è Test Your Work:**\n",
    "\n",
    "- Print the explained variance ratio of the principal components\n",
    "- Expected output: The percentage of variance explained by each principal component"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf98307",
   "metadata": {},
   "source": [
    "## Task 4: Evaluate Model Performance\n",
    "**Context:** Data scientists must compare different approaches to determine which yields the best model. Here, you'll evaluate whether feature selection with RFE or dimensionality reduction with PCA results in better predictive performance.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Split the RFE-selected data and the PCA-transformed data into training and testing sets\n",
    "2. Train a Linear Regression model on each training set\n",
    "3. Make predictions on the test sets\n",
    "4. Calculate and compare performance metrics (R-squared and MSE) for both approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967624d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate RFE model\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Evaluate PCA model\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Compare performance\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e001ae",
   "metadata": {},
   "source": [
    "**üí° Tip:** Use the same random state when splitting data to ensure a fair comparison between models.\n",
    "    \n",
    "**‚öôÔ∏è Test Your Work:**\n",
    "\n",
    "- Print the R-squared and MSE values for both models\n",
    "- Expected output: Performance metrics showing how well each model predicts house prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3167454",
   "metadata": {},
   "source": [
    "## Task 5: Analyze and Document Findings\n",
    "**Context:** In a real-world scenario, you would need to communicate your findings to stakeholders. This involves analyzing the trade-offs between different approaches and making recommendations.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Compare the performance of the RFE and PCA approaches\n",
    "2. Discuss the interpretability advantage of RFE (knowing specific important features) versus the potential information preservation of PCA\n",
    "3. Document which features RFE selected and why they might be important for house price prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e90400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document your findings\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e66ac7",
   "metadata": {},
   "source": [
    "**üí° Tip:** Consider both quantitative metrics and qualitative aspects like interpretability in your analysis.\n",
    "    \n",
    "**‚öôÔ∏è Test Your Work:**\n",
    "\n",
    "- Write a concise summary of your findings\n",
    "- Expected output: A clear analysis comparing the two approaches with specific metrics and insights\n",
    "\n",
    "## ‚úÖ Success Checklist\n",
    "- Successfully loaded and preprocessed the Ames Housing dataset\n",
    "- Applied RFE to identify the 5 most important features\n",
    "- Implemented PCA for dimensionality reduction\n",
    "- Trained and evaluated linear regression models using both approaches\n",
    "- Compared performance metrics between RFE and PCA approaches\n",
    "- Documented insights about feature importance and selection trade-offs\n",
    "- Code runs without errors\n",
    "\n",
    "## üîç Common Issues & Solutions\n",
    "**Problem:** RFE takes a long time to run. \n",
    "\n",
    "**Solution:** Start with a smaller subset of features or use `RFECV` with cross-validation to find the optimal number of features more efficiently.\n",
    "\n",
    "**Problem:** Poor model performance even after feature selection. \n",
    "\n",
    "**Solution:** Consider trying different base estimators for RFE or exploring other preprocessing techniques for the dataset.\n",
    "\n",
    "**Problem:** PCA components are difficult to interpret. \n",
    "\n",
    "**Solution:** This is a natural trade-off with PCA. If interpretability is critical, feature selection methods like RFE might be more appropriate than PCA.\n",
    "\n",
    "## üîë Key Points\n",
    "- Feature selection techniques like RFE help identify the most predictive features, improving model interpretability.\n",
    "- PCA reduces dimensionality while preserving variance but sacrifices the direct interpretability of features.\n",
    "- The choice between feature selection and dimensionality reduction depends on your specific goals and requirements.\n",
    "- Always evaluate and compare model performance to make data-driven decisions about feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d201bf",
   "metadata": {},
   "source": [
    "## üíª Exemplar Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c0f949",
   "metadata": {},
   "source": [
    "<details>\n",
    "\n",
    "<summary><strong>Click HERE to see an exemplar solution</strong></summary>    \n",
    "    \n",
    "```python\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# Load the Ames Housing dataset\n",
    "ames = fetch_openml(name=\"house_prices\", as_frame=True)\n",
    "data = ames.data\n",
    "data['SalePrice'] = ames.target\n",
    "print(data.head())\n",
    "print(data.describe())\n",
    "\n",
    "\n",
    "# Basic data preprocessing\n",
    "# Handle missing values\n",
    "data = data.select_dtypes(include=[np.number])  # Select only numerical features for simplicity\n",
    "data = data.fillna(data.median())\n",
    "\n",
    "\n",
    "# Define features and target\n",
    "X = data.drop('SalePrice', axis=1)\n",
    "y = data['SalePrice'].astype(float)\n",
    "\n",
    "\n",
    "# Apply Recursive Feature Elimination (RFE)\n",
    "model = LinearRegression()\n",
    "rfe = RFE(model, n_features_to_select=5)\n",
    "X_rfe = rfe.fit_transform(X, y)\n",
    "\n",
    "\n",
    "selected_features = X.columns[rfe.support_]\n",
    "print(\"Selected Features:\", selected_features)\n",
    "\n",
    "\n",
    "# Explore PCA\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "\n",
    "print(\"Explained Variance Ratio by PCA:\", pca.explained_variance_ratio_)\n",
    "\n",
    "\n",
    "# Evaluate Model Performance with RFE features\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_rfe, y, test_size=0.2, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred_rfe = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"RFE Model - R-squared:\", r2_score(y_test, y_pred_rfe))\n",
    "print(\"RFE Model - MSE:\", mean_squared_error(y_test, y_pred_rfe))\n",
    "\n",
    "\n",
    "# Evaluate Model Performance with PCA-transformed data\n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "model.fit(X_train_pca, y_train_pca)\n",
    "y_pred_pca = model.predict(X_test_pca)\n",
    "\n",
    "\n",
    "print(\"PCA Model - R-squared:\", r2_score(y_test_pca, y_pred_pca))\n",
    "print(\"PCA Model - MSE:\", mean_squared_error(y_test_pca, y_pred_pca))\n",
    "\n",
    "\n",
    "# Analyze and Document Findings\n",
    "print(\"\\nAnalysis of Results:\")\n",
    "print(f\"The top 5 features selected by RFE are: {', '.join(selected_features)}\")\n",
    "print(f\"RFE model performance: R¬≤ = {r2_score(y_test, y_pred_rfe):.4f}, MSE = {mean_squared_error(y_test, y_pred_rfe):.2f}\")\n",
    "print(f\"PCA model performance: R¬≤ = {r2_score(y_test_pca, y_pred_pca):.4f}, MSE = {mean_squared_error(y_test_pca, y_pred_pca):.2f}\")\n",
    "\n",
    "```    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
