{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ff04618",
   "metadata": {},
   "source": [
    "# üë©‚Äçüíª HR Attrition Prediction with Decision Trees and Random Forests\n",
    "\n",
    "## üìã Overview\n",
    "In this lab, you'll use decision trees and random forests to predict employee attrition based on HR analytics data. You'll build and compare these models, then identify the key factors contributing to attrition. This will show how tree-based algorithms can help human resources understand and improve employee retention.\n",
    "\n",
    "## üéØ Learning Outcomes\n",
    "By the end of this lab, you will be able to:\n",
    "- In this lab, you'll clean and prepare HR attrition data for machine learning. \n",
    "- You'll then use decision trees and random forests to predict attrition, evaluating and comparing their performance. \n",
    "- Finally, you'll analyze feature importance to identify key indicators driving employee satisfaction, interpreting these insights within an organization context. \n",
    "- This will show how tree-based algorithms can be applied to identify risk factors and potentially improve employee outcomes.\n",
    "\n",
    "## üöÄ Starting Point\n",
    "Start with the provided starter code which includes necessary imports and data loading functionality:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df446eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "First 5 records:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1102</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>279</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1373</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>1392</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>591</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Attrition     BusinessTravel  DailyRate              Department  \\\n",
       "0   41       Yes      Travel_Rarely       1102                   Sales   \n",
       "1   49        No  Travel_Frequently        279  Research & Development   \n",
       "2   37       Yes      Travel_Rarely       1373  Research & Development   \n",
       "3   33        No  Travel_Frequently       1392  Research & Development   \n",
       "4   27        No      Travel_Rarely        591  Research & Development   \n",
       "\n",
       "   DistanceFromHome  Education EducationField  EmployeeCount  EmployeeNumber  \\\n",
       "0                 1          2  Life Sciences              1               1   \n",
       "1                 8          1  Life Sciences              1               2   \n",
       "2                 2          2          Other              1               4   \n",
       "3                 3          4  Life Sciences              1               5   \n",
       "4                 2          1        Medical              1               7   \n",
       "\n",
       "   ...  RelationshipSatisfaction StandardHours  StockOptionLevel  \\\n",
       "0  ...                         1            80                 0   \n",
       "1  ...                         4            80                 1   \n",
       "2  ...                         2            80                 0   \n",
       "3  ...                         3            80                 0   \n",
       "4  ...                         4            80                 1   \n",
       "\n",
       "   TotalWorkingYears  TrainingTimesLastYear WorkLifeBalance  YearsAtCompany  \\\n",
       "0                  8                      0               1               6   \n",
       "1                 10                      3               3              10   \n",
       "2                  7                      3               3               0   \n",
       "3                  8                      3               3               8   \n",
       "4                  6                      3               3               2   \n",
       "\n",
       "  YearsInCurrentRole  YearsSinceLastPromotion  YearsWithCurrManager  \n",
       "0                  4                        0                     5  \n",
       "1                  7                        1                     7  \n",
       "2                  0                        0                     0  \n",
       "3                  7                        3                     0  \n",
       "4                  2                        2                     2  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"WA_Fn-UseC_-HR-Employee-Attrition.csv\")\n",
    "\n",
    "print(\"Dataset loaded successfully.\")\n",
    "print(\"First 5 records:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6417e191",
   "metadata": {},
   "source": [
    "## Task 1: Data Exploration\n",
    "**Context:** Before building any machine learning model, it's essential to understand the dataset structure and characteristics, especially in the HR department where data quality directly impacts company outcomes.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Display the first few rows of the dataset using `head()` to understand its structure\n",
    "2. Examine the statistical summary of the data using `describe()`\n",
    "3. Check for missing values using the `isnull().sum()` method\n",
    "4. Explore the balance of the target variable (Consider Attrition as the target variable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44047a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your data exploration code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eddae0",
   "metadata": {},
   "source": [
    "**üí° Tip:** Pay special attention to the distribution of the target variable to determine if your dataset is balanced or imbalanced, as this will impact your model evaluation approach.\n",
    "\n",
    "**‚öôÔ∏è Test Your Work:**\n",
    "\n",
    "- Execute your data exploration code and verify you can answer: How many features are in the dataset? Are there any missing values?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302aa225",
   "metadata": {},
   "source": [
    "## Task 2: Data Cleaning and Preparation\n",
    "**Context:** HR datasets often contain missing values or require feature engineering. Proper preprocessing ensures your model makes accurate predictions.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Handle any missing values in the dataset (if present)\n",
    "2. Handle categorical features, if any (e.g., using one-hot encoding with pandas.get_dummies)\n",
    "3. Select relevant features for your model (This is important, try to check if you can find some features that are not relevant or have no explanatory power).\n",
    "4. Separate features (X) and target variable (y)\n",
    "5. Split the data into training and testing sets using `train_test_split()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e06c7fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your data cleaning and preparation code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaa4805",
   "metadata": {},
   "source": [
    "**üí° Tip:** For HR data, carefully consider how to handle missing values. Simple imputation with mean values might not always be appropriate depending on the HR context.\n",
    "\n",
    "**‚öôÔ∏è Test Your Work:**\n",
    "\n",
    "Check the shape of your X_train, X_test, y_train, and y_test to confirm proper splitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e780dd",
   "metadata": {},
   "source": [
    "## Task 3: Decision Tree Model Implementation\n",
    "**Context:** Decision trees provide an interpretable approach to explain attrition in this case, making them valuable in understanding the model's decision process is crucial.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Initialize a DecisionTreeClassifier with appropriate parameters to prevent overfitting (consider setting `max_depth`)\n",
    "2. Fit the model to your training data\n",
    "3. Make predictions on the test set\n",
    "4. Calculate the accuracy using `accuracy_score()`\n",
    "5. Generate a classification report using `classification_report()`\n",
    "6. Visualize the confusion matrix using `ConfusionMatrixDisplay`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3865430d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your decision tree implementation code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbc5dc0",
   "metadata": {},
   "source": [
    "**üí° Tip:** Try different values of max_depth to find a balance between model complexity and accuracy.\n",
    "\n",
    "**‚öôÔ∏è Test Your Work:**\n",
    "\n",
    "Your decision tree should output an accuracy score and display a confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a59f3f",
   "metadata": {},
   "source": [
    "## Task 4: Random Forest Model Implementation\n",
    "**Context:** Random Forest models often provide better predictive performance than single decision trees by reducing overfitting, which is crucial for reliable attrition risk prediction.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Initialize a RandomForestClassifier with an appropriate number of estimators\n",
    "2. Train the model on your training data\n",
    "3. Generate predictions on the test set\n",
    "4. Evaluate model performance using accuracy and a classification report\n",
    "5. Create a confusion matrix visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b612b729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your random forest implementation code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6868750e",
   "metadata": {},
   "source": [
    "**üí° Tip:** Random forests typically perform better with default parameters than decision trees, but you can still experiment with n_estimators and max_depth to optimize performance.\n",
    "\n",
    "**‚öôÔ∏è Test Your Work:**\n",
    "\n",
    "Compare the accuracy of your random forest model with the decision tree model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b494028",
   "metadata": {},
   "source": [
    "## Task 5: Feature Importance Analysis\n",
    "**Context:** Understanding which factors most strongly influence the attrition can guide the relevant teams to understand how to be pro-active to prevent attrition..\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Extract feature importance scores from your Random Forest model\n",
    "2. Sort features by their importance\n",
    "3. Create a bar plot visualizing the importance of each feature\n",
    "4. Analyze which variables have the highest importance in terms of explaining the target variable.\n",
    "5. Add a comparison between the two models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faf4a8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your feature importance analysis code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25655930",
   "metadata": {},
   "source": [
    "**üí° Tip:** Connect the feature importance findings back to real-world HR implications.\n",
    "\n",
    "**‚öôÔ∏è Test Your Work:** Your visualization should clearly show which features have the highest importance scores\n",
    "\n",
    "## ‚úÖ Success Checklist\n",
    "- Dataset is properly loaded and explored\n",
    "- Data cleaning steps are implemented appropriately\n",
    "- Decision Tree model is trained and evaluated\n",
    "- Random Forest model is trained and compared to the Decision Tree\n",
    "- Feature importances are extracted and visualized\n",
    "- All visualizations are properly labeled and interpretable\n",
    "- Program runs without errors\n",
    "\n",
    "## üîç Common Issues & Solutions\n",
    "**Problem:** Low model accuracy \n",
    "- **Solution:** Try adjusting hyperparameters like max_depth for Decision Trees or n_estimators for Random Forests\n",
    "\n",
    "**Problem:** Feature importance visualization is unclear \n",
    "- **Solution:** Sort features by importance and limit to top N features if you have many variables\n",
    "\n",
    "## üîë Key Points\n",
    "- Decision trees provide interpretable models but may suffer from overfitting\n",
    "- Random forests typically offer better performance by averaging multiple decision trees\n",
    "- Feature importance analysis provides valuable insights for this dataset but generally any dataset to understand how the outcomes are determined by the feature variables. This is an iterative process.\n",
    "- Model evaluation should consider multiple metrics beyond just accuracy, especially for HR applications\n",
    "\n",
    "## ‚û°Ô∏è Next Steps\n",
    "In future labs, you'll explore more advanced ensemble methods and apply these techniques to more complex datasets. You'll also learn how to perform hyperparameter tuning to optimize your models further.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44d7a95",
   "metadata": {},
   "source": [
    "## Exemplar Solution\n",
    "After completing this activity (or if you get stuck!), take a moment to review the exemplar solution. This sample solution can offer insights into different techniques and approaches. Reflect on what you can learn from the exemplar solution to improve your coding skills. Remember, multiple solutions can exist for some problems; the goal is to learn and grow as a programmer by exploring various approaches. Use the exemplar solution as a learning tool to enhance your understanding and refine your approach to coding challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645b6b80",
   "metadata": {},
   "source": [
    "<details>\n",
    "\n",
    "<summary><strong>Click HERE to see an exemplar solution</strong></summary>    \n",
    "    \n",
    "```python\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"WA_Fn-UseC_-HR-Employee-Attrition.csv\")\n",
    "\n",
    "print(\"Dataset loaded successfully.\")\n",
    "print(\"First 5 records:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\n--- Dataset Info ---\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\n--- Dataset Description ---\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\n--- Missing Values ---\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# For this HR dataset, let's look at the target variable distribution\n",
    "if 'Attrition' in df.columns:\n",
    "    print(\"\\n--- Attrition Distribution ---\")\n",
    "    print(df['Attrition'].value_counts())\n",
    "    sns.countplot(x='Attrition', data=df)\n",
    "    plt.title('Distribution of Attrition')\n",
    "    plt.show()\n",
    "\n",
    "# Identify features (X) and target (y)\n",
    "# For the IBM HR Analytics dataset, 'Attrition' is the target variable.\n",
    "# We'll drop 'EmployeeCount', 'StandardHours', 'Over18', and 'EmployeeNumber'\n",
    "# as they are constant or unique identifiers with no predictive power.\n",
    "if 'Attrition' in df.columns:\n",
    "    y = df['Attrition']\n",
    "    X = df.drop(['Attrition', 'EmployeeCount', 'StandardHours', 'Over18', 'EmployeeNumber'], axis=1, errors='ignore') # errors='ignore' prevents error if column already dropped\n",
    "else:\n",
    "    print(\"Error: 'Attrition' column not found. Please ensure the correct dataset is loaded.\")\n",
    "    # Fallback for dummy dataset\n",
    "    X = df.drop('target', axis=1)\n",
    "    y = df['target']\n",
    "    print(\"Using dummy dataset for preprocessing.\")\n",
    "\n",
    "\n",
    "# Convert 'Attrition' target to numerical (Yes=1, No=0)\n",
    "if y.dtype == 'object':\n",
    "    y = y.map({'Yes': 1, 'No': 0})\n",
    "    print(\"Converted 'Attrition' to numerical (Yes=1, No=0).\")\n",
    "\n",
    "# One-hot encode categorical features in X\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "print(\"\\n--- Features after One-Hot Encoding ---\")\n",
    "print(X.head())\n",
    "print(f\"Number of features after encoding: {X.shape[1]}\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "# Using stratify=y helps maintain the same proportion of target classes in both train and test sets,\n",
    "# which is important for imbalanced datasets like this one.\n",
    "\n",
    "print(f\"\\nTraining set shape: {X_train.shape}, Test set shape: {X_test.shape}\")\n",
    "\n",
    "print(\"\\n--- Running Decision Tree Classifier ---\")\n",
    "# Initialize and train the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_dt = dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the Decision Tree model\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_dt):.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "\n",
    "print(\"\\n--- Running Random Forest Classifier ---\")\n",
    "# Initialize and train the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42) # n_estimators is the number of trees\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Feature Importance for Random Forest\n",
    "print(\"\\n--- Random Forest Feature Importance ---\")\n",
    "feature_importances = pd.Series(rf_classifier.feature_importances_, index=X.columns)\n",
    "# Get top 10 features\n",
    "top_10_features = feature_importances.nlargest(10)\n",
    "print(top_10_features)\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "top_10_features.sort_values(ascending=True).plot(kind='barh')\n",
    "plt.title('Top 10 Random Forest Feature Importances')\n",
    "plt.xlabel('Importance')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n--- Model Comparison ---\")\n",
    "dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Decision Tree Accuracy: {dt_accuracy:.4f}\")\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "print(\"--Insights--\")\n",
    "\n",
    "if rf_accuracy > dt_accuracy:\n",
    "    print(\"\\nThe **Random Forest Classifier** performed better than the Decision Tree in terms of accuracy.\")\n",
    "    print(\"This is often expected, as Random Forest is an ensemble method that combines multiple decision trees, reducing overfitting and improving generalization.\")\n",
    "elif dt_accuracy > rf_accuracy:\n",
    "    print(\"\\nIn this particular run, the **Decision Tree Classifier** had slightly higher accuracy.\")\n",
    "    print(\"While less common, this can happen depending on the dataset characteristics or if the Random Forest hyperparameters aren't optimally tuned.\")\n",
    "else:\n",
    "    print(\"\\nBoth models achieved similar accuracy.\")\n",
    "\n",
    "    \n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
