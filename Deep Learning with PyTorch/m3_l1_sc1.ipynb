{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# How RNNs Process Sequential Data: Concepts and Input Flow"
      ],
      "metadata": {
        "id": "F1TUaxJpnoFB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Setting Up the Environment for RNNs in PyTorch\n"
      ],
      "metadata": {
        "id": "1HoSrwvwnnua"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wf7wj0RncLv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Defining an RNN in PyTorch\n"
      ],
      "metadata": {
        "id": "t4scV3OAnw07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers):\n",
        "        super(SimpleRNN, self).__init__()\n",
        "        # Store parameters\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Define the RNN layers\n",
        "        # batch_first=True means input and output tensors are provided as (batch, seq, feature)\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "\n",
        "        # Define the fully connected output layer\n",
        "        self.fc = nn.Linear(hidden_size, 1) # Outputting a single value\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input x shape: (batch_size, seq_length, input_size)\n",
        "\n",
        "        # Initialize hidden state with zeros\n",
        "        # h0 shape: (num_layers * D, batch_size, hidden_size), D=1 for unidirectional\n",
        "        # Ensure h0 is on the same device as x\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "\n",
        "        # Forward propagate the RNN\n",
        "        # rnn_out shape: (batch_size, seq_length, hidden_size) - Output features (h_t) from the last layer of the RNN, for each t\n",
        "        # hn shape: (num_layers * D, batch_size, hidden_size) - Final hidden state for each element in the batch. D=1 for unidirectional.\n",
        "        rnn_out, hn = self.rnn(x, h0)\n",
        "\n",
        "        # Decode the hidden state of the last time step\n",
        "        # We take the output of the last time step from the RNN's last layer: rnn_out[:, -1, :]\n",
        "        # Shape of rnn_out[:, -1, :]: (batch_size, hidden_size)\n",
        "        out = self.fc(rnn_out[:, -1, :])\n",
        "        # out shape: (batch_size, output_size_of_fc) which is (batch_size, 1) here\n",
        "        return out"
      ],
      "metadata": {
        "id": "EWchgHu7n2OA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Flowing Data Through an RNN\n"
      ],
      "metadata": {
        "id": "hRtcjzIanuMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model and data parameters\n",
        "input_dim = 1       # Number of features in input at each time step\n",
        "hidden_dim = 5      # Number of features in the hidden state\n",
        "layer_dim = 1       # Number of recurrent layers in the RNN\n",
        "batch_size = 1      # Number of sequences to process in parallel\n",
        "seq_len = 10        # Number of time steps in each sequence\n",
        "\n",
        "# Simulate sequential input data\n",
        "# We'll use a simple sine wave as our sequence\n",
        "time_steps = np.linspace(0, np.pi, seq_len)  # Generate 10 time steps from 0 to pi\n",
        "data = np.sin(time_steps)                    # Compute sin values for these time steps\n",
        "\n",
        "# Reshape data for RNN: (batch_size, seq_length, input_size)\n",
        "# Our data is (10,) -> needs to be (1, 10, 1)\n",
        "data_reshaped = data.reshape((batch_size, seq_len, input_dim))\n",
        "input_tensor = torch.tensor(data_reshaped, dtype=torch.float32)\n",
        "\n",
        "print(f\"--- Input Data ---\")\n",
        "print(f\"Original data shape: {data.shape}\")\n",
        "print(f\"Input tensor shape (batch_size, seq_length, input_size): {input_tensor.shape}\")\n",
        "print(f\"Input tensor sample (first batch, first 5 time steps, first feature): \\n{input_tensor[0, :5, 0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKO95spin7FL",
        "outputId": "0fb994d4-b855-4426-8eb7-2a8a344c8ae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Input Data ---\n",
            "Original data shape: (10,)\n",
            "Input tensor shape (batch_size, seq_length, input_size): torch.Size([1, 10, 1])\n",
            "Input tensor sample (first batch, first 5 time steps, first feature): \n",
            "tensor([0.0000, 0.3420, 0.6428, 0.8660, 0.9848])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model\n",
        "model = SimpleRNN(input_size=input_dim, hidden_size=hidden_dim, num_layers=layer_dim)\n",
        "print(f\"\\n--- Model Architecture ---\")\n",
        "print(model)\n",
        "\n",
        "# To understand hidden states and RNN layer outputs, let's inspect them.\n",
        "# First, create an initial hidden state h0 (as done in model.forward)\n",
        "# h0 shape for nn.RNN: (num_layers * D, batch_size, hidden_size), D=1 for unidirectional\n",
        "h0_for_inspection = torch.zeros(layer_dim, input_tensor.size(0), hidden_dim).to(input_tensor.device)\n",
        "\n",
        "# Manually pass data through the RNN layer only (model.rnn) to see its direct outputs\n",
        "# rnn_layer_output: contains output features (h_t) from the last layer of the RNN, for each time step t.\n",
        "# rnn_layer_hn: is the final hidden state (at the last time step) for each layer.\n",
        "rnn_layer_output, rnn_layer_hn = model.rnn(input_tensor, h0_for_inspection)\n",
        "\n",
        "print(f\"\\n--- Inspecting RNN Layer Outputs (model.rnn) ---\")\n",
        "print(f\"Shape of rnn_layer_output (batch_size, seq_length, hidden_size): {rnn_layer_output.shape}\")\n",
        "print(f\"Shape of rnn_layer_hn (num_layers, batch_size, hidden_size): {rnn_layer_hn.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K342Mee8o1Kz",
        "outputId": "73d7b27f-fd89-46b9-a650-785bfd848b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model Architecture ---\n",
            "SimpleRNN(\n",
            "  (rnn): RNN(1, 5, batch_first=True)\n",
            "  (fc): Linear(in_features=5, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            "--- Inspecting RNN Layer Outputs (model.rnn) ---\n",
            "Shape of rnn_layer_output (batch_size, seq_length, hidden_size): torch.Size([1, 10, 5])\n",
            "Shape of rnn_layer_hn (num_layers, batch_size, hidden_size): torch.Size([1, 1, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, let's get the final output from the complete model's forward pass\n",
        "# This includes passing the RNN output through the fully connected layer (model.fc)\n",
        "final_output = model(input_tensor)\n",
        "\n",
        "print(f\"\\n--- Model's Final Output (after FC layer) ---\")\n",
        "print(f\"Final model output shape (batch_size, fc_output_size): {final_output.shape}\")\n",
        "# .item() is used to get the Python number from a tensor containing a single value.\n",
        "print(f\"Final model output value: {final_output.item():.4f}\")\n",
        "\n",
        "# For further illustration, let's show what rnn_out[:, -1, :] (from the forward pass) means:\n",
        "# This is the hidden state of the last time step, from the last RNN layer.\n",
        "last_time_step_hidden_activity = rnn_layer_output[:, -1, :]\n",
        "print(f\"\\n--- Last Time Step's Hidden Activity (used by FC layer) ---\")\n",
        "print(f\"Shape: {last_time_step_hidden_activity.shape}\") # (batch_size, hidden_size) -> (1, 5)\n",
        "print(f\"Value (first batch): \\n{last_time_step_hidden_activity[0]}\")\n",
        "\n",
        "# This last_time_step_hidden_activity is what's fed into the model.fc layer.\n",
        "# We can verify by manually passing it through model.fc:\n",
        "fc_output_manual = model.fc(last_time_step_hidden_activity)\n",
        "print(f\"\\nOutput if manually passing last_time_step_hidden_activity to model.fc: {fc_output_manual.item():.4f}\")\n",
        "print(f\"This should match the model's final output value: {final_output.item():.4f} == {fc_output_manual.item():.4f} -> {(final_output.item() == fc_output_manual.item())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgooLq8TorYw",
        "outputId": "17c571bf-f676-4dd5-870b-e9d47ff32fd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model's Final Output (after FC layer) ---\n",
            "Final model output shape (batch_size, fc_output_size): torch.Size([1, 1])\n",
            "Final model output value: -0.0877\n",
            "\n",
            "--- Last Time Step's Hidden Activity (used by FC layer) ---\n",
            "Shape: torch.Size([1, 5])\n",
            "Value (first batch): \n",
            "tensor([-0.2459, -0.4186,  0.2501,  0.4190, -0.4264],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "\n",
            "Output if manually passing last_time_step_hidden_activity to model.fc: -0.0877\n",
            "This should match the model's final output value: -0.0877 == -0.0877 -> True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6122kPJfo331"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}