{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc449b3b",
   "metadata": {},
   "source": [
    "# üë©‚Äçüíª Build a Basic RNN to Model Sequential Patterns\n",
    "\n",
    "## üìã Overview\n",
    "In this lab, you will build a Recurrent Neural Network (RNN) from scratch using PyTorch to model and predict character sequences. RNNs are powerful neural network architectures designed specifically for sequential data, maintaining a form of \"memory\" that allows them to learn patterns over time. You'll create a model that can recognize and predict the next character in repeating patterns, similar to how predictive text works in real-world applications.\n",
    "\n",
    "## üéØ Learning Outcomes\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "- Generate and prepare sequential data for RNN processing\n",
    "- Implement a basic RNN architecture using PyTorch's nn.RNN module\n",
    "- Train an RNN to recognize patterns in character sequences\n",
    "- Visualize and interpret the predictions of your RNN model\n",
    "\n",
    "## üöÄ Starting Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac70543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter code imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d28d06",
   "metadata": {},
   "source": [
    "Required tools/setup:\n",
    "\n",
    "- PyTorch installed\n",
    "- Matplotlib for visualization\n",
    "- Basic understanding of neural networks and tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b90332",
   "metadata": {},
   "source": [
    "## Task 1: Prepare Synthetic Sequential Data\n",
    "**Context:** In real-world applications like text prediction or DNA sequence analysis, we need to convert character sequences into numerical representations that neural networks can process.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Generate a simple repeating character sequence to serve as your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530ac263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a repeating sequence\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346991bc",
   "metadata": {},
   "source": [
    "2. Create mappings between characters and indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0844bc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create character to index and index to character mappings\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d278baa7",
   "metadata": {},
   "source": [
    "3. Convert your sequence into numerical format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4aba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert characters to indices\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353071f5",
   "metadata": {},
   "source": [
    "4. Create input and target tensors by offsetting the sequence by one position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac13072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input tensor (all but last character) and target tensor (all but first character)\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fef915",
   "metadata": {},
   "source": [
    "**üí° Tip:** For RNNs, your input is typically the current sequence, and your target is the sequence shifted by one position (to predict the next item in the sequence).\n",
    "\n",
    "**‚öôÔ∏è Test Your Work:**\n",
    "\n",
    "- Print your character mapping dictionaries\n",
    "- Verify the shapes of your input and target tensors\n",
    "- Expected output: Input shape should be [1, sequence_length-1, 1] and target should match but offset by one position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec52626",
   "metadata": {},
   "source": [
    "## Task 2: Build the RNN Model\n",
    "**Context:** RNNs are used in many industries for sequence modeling, from voice assistants predicting your next word to financial systems forecasting stock prices.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Define a basic RNN class using PyTorch's nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37d358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an RNN class inheriting from nn.Module\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86769bc8",
   "metadata": {},
   "source": [
    "2. Implement the constructor with appropriate layers\n",
    "    - Use nn.RNN for the recurrent layer\n",
    "    - Use nn.Linear for the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f507b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RNN and Linear layers\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a60a0c0",
   "metadata": {},
   "source": [
    "3. Implement the forward method to process sequences. The nn.RNN layer expects input shape [batch, sequence, input_size] (with batch_first=True) and outputs [batch, sequence, hidden_size]. The nn.Linear layer maps the hidden state to the output size (number of unique characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da512cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the forward pass\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e348d3d8",
   "metadata": {},
   "source": [
    "4. Add a helper method to initialize the hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef19473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a method to initialize the hidden state\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04beb313",
   "metadata": {},
   "source": [
    "5. Initialize your model with appropriate dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1263a683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model with input_size, hidden_size, and output_size\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a68d22d",
   "metadata": {},
   "source": [
    "**üí° Tip:** The `batch_first=True` parameter in nn.RNN changes the tensor shape requirement to [batch, sequence, features] which is often more intuitive to work with.\n",
    "\n",
    "**‚öôÔ∏è Test Your Work:**\n",
    "\n",
    "- Print your model architecture\n",
    "- Run a test sequence through the model\n",
    "- Expected output: A tensor of predictions and an updated hidden state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfceb74",
   "metadata": {},
   "source": [
    "## Task 3: Train the RNN\n",
    "**Context:** Training sequential models requires handling both the sequence data and evolving hidden states across time steps.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Define your loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e993cfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up loss function and optimizer\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731463d8",
   "metadata": {},
   "source": [
    "2. Create a training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d14bbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a loop for training iterations\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b55052",
   "metadata": {},
   "source": [
    "3. Inside the loop, initialize the hidden state for each sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0705d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize hidden state\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb5da65",
   "metadata": {},
   "source": [
    "4. Forward pass: get predictions from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae9014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab87e7bf",
   "metadata": {},
   "source": [
    "5. Calculate loss between predictions and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f52dd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate loss\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c33118c",
   "metadata": {},
   "source": [
    "6. Perform backpropagation and update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664c5eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward pass and optimization\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd77bd5",
   "metadata": {},
   "source": [
    "7. Track and store loss values for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4617f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store loss values\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407176e6",
   "metadata": {},
   "source": [
    "**üí° Tip:** Detaching the hidden state (hidden.detach_()) prevents backpropagation through the entire sequence history, which is useful for long sequences to avoid exploding gradients.\n",
    "\n",
    "**‚öôÔ∏è Test Your Work:**\n",
    "\n",
    "- Plot the training loss to verify it's decreasing\n",
    "- Expected output: A downward trending loss curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07643fac",
   "metadata": {},
   "source": [
    "## Task 4: Evaluate and Visualize Results\n",
    "**Context:** Visualization helps us understand the model's learning progress and performance on sequence prediction tasks.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Prepare the model for evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096c8924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model to evaluation mode\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97594a2",
   "metadata": {},
   "source": [
    "2. Generate predictions for a test sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6fa0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df8b9ad",
   "metadata": {},
   "source": [
    "3. Convert numerical predictions back to characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14252665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions to characters\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e22217f",
   "metadata": {},
   "source": [
    "4. Visualize the original sequence vs predicted sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d2b65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5649fb2",
   "metadata": {},
   "source": [
    "5. Create a visualization of the hidden state evolution over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39639d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize hidden state changes\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8e4d8c",
   "metadata": {},
   "source": [
    "**üí° Tip:** Use `torch.no_grad()` during evaluation to disable gradient calculations for efficiency.\n",
    "\n",
    "**‚öôÔ∏è Test Your Work:**\n",
    "\n",
    "- Compare the original and predicted sequences\n",
    "- Expected output: For a well-trained model, the predicted sequence should closely match the pattern of the training sequence\n",
    "\n",
    "## ‚úÖ Success Checklist\n",
    "- Successfully created and preprocessed a character sequence dataset\n",
    "- Built an RNN model with proper architecture\n",
    "- Trained the RNN model with decreasing loss\n",
    "- Generated predictions that match or approximate the expected sequence\n",
    "- Visualized both the predictions and hidden state evolution\n",
    "- Program runs without errors\n",
    "\n",
    "## üîç Common Issues & Solutions\n",
    "**Problem:** Loss doesn't decrease during training **Solution:** Check your learning rate (may be too high or low), ensure your input and target tensors are properly aligned, or try increasing the hidden layer size.\n",
    "\n",
    "**Problem:** Dimension mismatch errors **Solution:** Verify that your input tensor shape matches what the RNN expects. The typical format is [batch, sequence, features] when using batch_first=True.\n",
    "\n",
    "**Problem:** Poor prediction accuracy **Solution:** For complex sequences, try increasing the number of training iterations or the hidden size. Also ensure your sequence is properly encoded and decoded.\n",
    "\n",
    "## üîë Key Points\n",
    "- RNNs maintain a hidden state that acts as memory across sequence elements\n",
    "- The input and target data preparation is crucial for correct sequence learning\n",
    "- Understanding the dimensions of your data at each step is essential for RNN implementation\n",
    "- Visualization is a powerful tool to understand how your RNN is learning sequential patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87449872",
   "metadata": {},
   "source": [
    "## üíª Reference Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1c4486",
   "metadata": {},
   "source": [
    "<details>\n",
    "\n",
    "<summary><strong>Click HERE to see a reference solution</strong></summary>    \n",
    "    \n",
    "```python\n",
    "# Task 1: Prepare Synthetic Sequential Data\n",
    "# Create a repeating sequence\n",
    "sequence = \"abcabcabcabcabc\"  # Simple repeating pattern\n",
    "chars = sorted(list(set(sequence)))  # Get unique characters\n",
    "\n",
    "# Create character to index mappings\n",
    "char_to_idx = {ch: idx for idx, ch in enumerate(chars)}\n",
    "idx_to_char = {idx: ch for ch, idx in char_to_idx.items()}\n",
    "\n",
    "# Convert sequence to numerical format\n",
    "sequence_indices = [char_to_idx[ch] for ch in sequence]\n",
    "\n",
    "# Create input and target tensors\n",
    "input_tensor = torch.tensor(sequence_indices[:-1], dtype=torch.float32).view(1, -1, 1)\n",
    "target_tensor = torch.tensor(sequence_indices[1:], dtype=torch.long).view(1, -1)\n",
    "\n",
    "print(f\"Character mappings: {char_to_idx}\")\n",
    "print(f\"Input tensor shape: {input_tensor.shape}\")\n",
    "print(f\"Target tensor shape: {target_tensor.shape}\")\n",
    "\n",
    "# Task 2: Build the RNN Model\n",
    "class BasicRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(BasicRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size=1):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size)\n",
    "\n",
    "# Initialize model with appropriate dimensions\n",
    "input_size = 1  # Single feature (character index)\n",
    "hidden_size = 16  # Hidden layer size\n",
    "output_size = len(chars)  # Number of possible characters\n",
    "model = BasicRNN(input_size, hidden_size, output_size)\n",
    "\n",
    "print(model)\n",
    "\n",
    "# Task 3: Train the RNN\n",
    "# Set up loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 20\n",
    "losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Initialize hidden state\n",
    "    hidden = model.init_hidden()\n",
    "    \n",
    "    # Forward pass\n",
    "    output, hidden = model(input_tensor, hidden)\n",
    "    \n",
    "    # Reshape output for loss calculation\n",
    "    output = output.view(-1, output_size)\n",
    "    target = target_tensor.view(-1)\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss = criterion(output, target)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Store loss\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    # Print progress\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Plot loss curve\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(losses)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Task 4: Evaluate and Visualize Results\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Generate predictions\n",
    "with torch.no_grad():\n",
    "    hidden = model.init_hidden()\n",
    "    output, hidden = model(input_tensor, hidden)\n",
    "    \n",
    "    # Get predicted indices\n",
    "    _, predicted_indices = torch.max(output.view(-1, output_size), 1)\n",
    "    predicted_chars = [idx_to_char[idx.item()] for idx in predicted_indices]\n",
    "    \n",
    "    # Convert input to characters for comparison\n",
    "    input_chars = [idx_to_char[int(idx.item())] for idx in input_tensor.view(-1)]\n",
    "    target_chars = [idx_to_char[idx.item()] for idx in target_tensor.view(-1)]\n",
    "\n",
    "print(f\"Input sequence: {''.join(input_chars)}\")\n",
    "print(f\"Target sequence: {''.join(target_chars)}\")\n",
    "print(f\"Predicted sequence: {''.join(predicted_chars)}\")\n",
    "\n",
    "# Visualize predictions vs targets\n",
    "plt.figure(figsize=(12, 6))\n",
    "# Plot target with distinct style\n",
    "plt.plot(range(len(target_chars)), [char_to_idx[c] for c in target_chars], \n",
    "         'bo--', label='Target', markersize=8, alpha=0.8)\n",
    "# Plot predicted with distinct style and slight offset for visibility\n",
    "plt.plot([x + 0.1 for x in range(len(predicted_chars))], [char_to_idx[c] for c in predicted_chars], \n",
    "         'r*-', label='Predicted', markersize=8, alpha=0.8)\n",
    "plt.title('Target vs Predicted Characters')\n",
    "plt.xlabel('Position in Sequence')\n",
    "plt.ylabel('Character Index')\n",
    "plt.xticks(range(len(target_chars)), target_chars)  # Show characters on x-axis\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Visualize hidden state evolution\n",
    "with torch.no_grad():\n",
    "    hidden = model.init_hidden()\n",
    "    hidden_states = []\n",
    "    \n",
    "    for i in range(input_tensor.size(1)):\n",
    "        # Process one character at a time\n",
    "        char_input = input_tensor[:, i:i+1, :]\n",
    "        _, hidden = model(char_input, hidden)\n",
    "        hidden_states.append(hidden.clone().view(-1).numpy())\n",
    "    \n",
    "    hidden_states = np.array(hidden_states)\n",
    "\n",
    "# Plot hidden state evolution\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(min(hidden_size, 5)):  # Show first 5 dimensions\n",
    "    plt.plot(hidden_states[:, i], label=f'Hidden {i+1}')\n",
    "plt.title('Hidden State Evolution Over Sequence')\n",
    "plt.xlabel('Sequence Position')\n",
    "plt.ylabel('Hidden State Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "```    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
