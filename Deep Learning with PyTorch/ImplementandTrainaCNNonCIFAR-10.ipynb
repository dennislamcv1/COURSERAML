{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "597d86ab",
   "metadata": {},
   "source": [
    "# üë©‚Äçüíª Implement and Train a CNN on CIFAR-10\n",
    "\n",
    "## üìã Overview\n",
    "In this lab, you'll implement a Convolutional Neural Network (CNN) from scratch using PyTorch and train it on the CIFAR-10 dataset. CNNs are fundamental to modern computer vision applications - the skills you'll develop here are directly applicable to real-world scenarios like autonomous vehicle image recognition systems, medical diagnostic tools, and automated quality control in manufacturing.\n",
    "\n",
    "## üéØ Learning Outcomes\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "- Load and preprocess image datasets with appropriate transformations for CNN training\n",
    "- Design and implement a custom CNN architecture using PyTorch's neural network modules\n",
    "- Train a CNN model using optimization techniques including loss functions and gradient descent\n",
    "- Evaluate model performance using appropriate metrics and visualize predictions\n",
    "\n",
    "## üöÄ Starting Point\n",
    "Required tools/setup:\n",
    "\n",
    "- PyTorch installed (version 1.8+)\n",
    "- Matplotlib for visualization\n",
    "- At least 2GB of free disk space for dataset\n",
    "\n",
    "Make sure to reference:\n",
    "\n",
    "- The previous lab on neural network fundamentals\n",
    "- Basic understanding of convolutional operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68af002f",
   "metadata": {},
   "source": [
    "## Task 1: Loading and Preparing the CIFAR-10 Dataset\n",
    "**Context:** In industry applications, properly preparing image data is crucial for model performance. The CIFAR-10 dataset is a standard benchmark containing 60,000 32√ó32 color images in 10 different classes.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Import the necessary libraries for working with PyTorch and the CIFAR-10 dataset\n",
    "\n",
    "    - Use `torch`, `torchvision.datasets`, `torchvision.transforms`, and `torch.utils.data`\n",
    "    - Consider what transformations will normalize the data appropriately\n",
    "\n",
    "2. Define transformations to prepare the images\n",
    "\n",
    "    - Apply `transforms.ToTensor()` to convert images to PyTorch tensors\n",
    "    - Use `transforms.Normalize()` with appropriate mean and standard deviation values\n",
    "    - Think about: Why is normalization important for neural network training?\n",
    "\n",
    "3. Load the CIFAR-10 dataset using the defined transformations\n",
    "\n",
    "    - Use `torchvision.datasets.CIFAR10()` with appropriate parameters\n",
    "    - Set `download=True` to automatically retrieve the dataset\n",
    "\n",
    "4. Create data loaders for both training and testing sets\n",
    "\n",
    "    - Use `torch.utils.data.DataLoader`\n",
    "    - Consider: How does batch size affect training?\n",
    "    - What's the purpose of shuffling the training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2037ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "# Task 1: Loading and preparing the dataset\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffb52ac",
   "metadata": {},
   "source": [
    "**üí° Tip:** The CIFAR-10 images are RGB with pixel values from 0-255, so normalizing with mean=(0.5, 0.5, 0.5) and std=(0.5, 0.5, 0.5) scales them to the [-1, 1] range.\n",
    "This specific normalization (mean=0.5, std=0.5 for each RGB channel) is a common convention that shifts and scales the original [0,1] pixel values (after ToTensor) to a symmetric range of [-1, 1], often leading to more stable training.\n",
    "\n",
    "**‚öôÔ∏è Test Your Work:**\n",
    "\n",
    "- Print the shape of a batch from the data loader - you should see [batch_size, 3, 32, 32]\n",
    "- Display a few sample images to verify they load correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb3ef06",
   "metadata": {},
   "source": [
    "## Task 2: Designing the CNN Architecture\n",
    "**Context:** When working on image classification projects, choosing the right CNN architecture directly impacts performance. The architecture you design must effectively extract features from the images while balancing computational efficiency.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Create a CNN class that inherits from `nn.Module`\n",
    "\n",
    "    - Use `torch.nn` to define your neural network\n",
    "    - Initialize the class with appropriate layers\n",
    "\n",
    "2. Define convolutional layers to extract image features\n",
    "\n",
    "    - Use `nn.Conv2d()` to create convolutional layers\n",
    "    - Consider kernel size, stride, and output channels\n",
    "    - Think about: How does increasing the number of filters affect feature extraction?\n",
    "\n",
    "3. Add pooling layers to reduce spatial dimensions\n",
    "\n",
    "    - Implement `nn.MaxPool2d()` or use functional `F.max_pool2d()`\n",
    "    - Consider: What's the purpose of pooling in CNNs?\n",
    "\n",
    "4. Add fully connected layers to perform classification\n",
    "\n",
    "    - Use `nn.Linear()` for classification layers\n",
    "    - Calculate the correct input dimensions based on your conv/pool operations\n",
    "    - Think about: How many output neurons do you need for CIFAR-10?\n",
    "\n",
    "5. Implement the forward method to connect all layers\n",
    "\n",
    "    - Define the data flow through your network\n",
    "    - Add appropriate activation functions (e.g., ReLU)\n",
    "    - Use proper reshaping between convolutional and linear layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614a7402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Designing the CNN Architecture\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713a8293",
   "metadata": {},
   "source": [
    "**üí° Tip:** Remember to calculate the output dimensions after each convolutional and pooling layer to determine the correct input size for your first fully connected layer.\n",
    "To calculate the input size for your first fully connected layer, track the spatial dimensions and channel count after each convolutional and pooling operation. For example, if a 32x32 image passes through a pooling layer with kernel_size=2, stride=2, its spatial dimensions will become 16x16. This applies to all channels.\n",
    "\n",
    "**‚öôÔ∏è Test Your Work:**\n",
    "\n",
    "- Create an instance of your model and print its architecture\n",
    "- Pass a sample batch through the model to verify the output shape is [batch_size, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03b0a80",
   "metadata": {},
   "source": [
    "## Task 3: Training the CNN Model\n",
    "Context: Training deep learning models requires careful configuration of optimizers, loss functions, and training loops. In production environments, engineers must monitor training progress and adjust parameters accordingly.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Define the loss function and optimizer\n",
    "\n",
    "    - Use `nn.CrossEntropyLoss()` for multiclass classification\n",
    "    - Choose an appropriate optimizer (`optim.SGD` or `optim.Adam`)\n",
    "    - Set a suitable learning rate\n",
    "    - Consider: How does learning rate affect training stability and speed?\n",
    "\n",
    "2. Create a training loop to iterate through epochs and batches\n",
    "\n",
    "    - Loop through a specified number of epochs\n",
    "    - For each epoch, iterate through the training data loader\n",
    "\n",
    "3. Implement the forward and backward passes in the training loop\n",
    "\n",
    "    - Zero gradients with `optimizer.zero_grad()`\n",
    "    - Compute model outputs and loss\n",
    "    - Perform backpropagation with `loss.backward()`\n",
    "    - Update weights with `optimizer.step()`\n",
    "\n",
    "4. Track and display training progress\n",
    "\n",
    "    - Calculate running loss during training\n",
    "    - Print loss statistics at regular intervals\n",
    "    - Consider: What patterns should you look for in the loss values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0654ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Training the CNN Model\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6767d173",
   "metadata": {},
   "source": [
    "**üí° Tip:** To debug training issues, implement a validation step after each epoch to check if the model is learning or overfitting.\n",
    "\n",
    "**‚öôÔ∏è Test Your Work:**\n",
    "\n",
    "- Monitor the loss values during training - they should decrease over time\n",
    "- Check that validation accuracy improves as training progresses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52addaed",
   "metadata": {},
   "source": [
    "## Task 4: Evaluating Model Performance\n",
    "**Context:** In practical applications, model evaluation provides crucial information about deployment readiness. Stakeholders need clear metrics and visualizations to understand model capabilities.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Create an evaluation loop for the test dataset\n",
    "\n",
    "    - Iterate through the test data loader\n",
    "    - Use `torch.no_grad()` to disable gradient calculation\n",
    "    - Think about: Why do we disable gradients during evaluation?\n",
    "\n",
    "2. Calculate accuracy and other performance metrics\n",
    "\n",
    "    - Compare model predictions to ground truth labels\n",
    "    - Compute overall accuracy percentage\n",
    "    - Consider calculating per-class accuracy\n",
    "\n",
    "3. Visualize model predictions on sample images\n",
    "\n",
    "    - Select a batch of test images\n",
    "    - Get model predictions for these images\n",
    "    - Display the images with both predicted and actual labels\n",
    "    - Think about: What patterns do you observe in the model's mistakes?\n",
    "\n",
    "4. Analyze model performance and identify improvement areas\n",
    "\n",
    "    - Look for classes that are frequently confused\n",
    "    - Consider how the model might be improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1e2c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: Evaluating Model Performance\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def1a3e8",
   "metadata": {},
   "source": [
    "**üí° Tip:** Create a confusion matrix to see which classes are most often confused with each other.\n",
    "\n",
    "**‚öôÔ∏è Test Your Work:**\n",
    "\n",
    "- Verify that accuracy calculation is implemented correctly\n",
    "- Check that visualizations clearly show both correct and incorrect predictions\n",
    "\n",
    "## ‚úÖ Success Checklist\n",
    "- Dataset loaded with appropriate transformations\n",
    "- CNN model architecture defined with convolutional, pooling, and fully connected layers\n",
    "- Training loop implemented with loss function and optimizer\n",
    "- Model evaluation showing test accuracy above 50% (baseline for CIFAR-10)\n",
    "- Visualizations of model predictions that clearly show performance\n",
    "- Program runs without errors\n",
    "\n",
    "## üîç Common Issues & Solutions\n",
    "**Problem:** Model accuracy is extremely low (around 10%) **Solution:** Check for normalization issues or ensure your model architecture is correctly implemented.\n",
    "\n",
    "**Problem:** \"CUDA out of memory\" error **Solution:** Reduce batch size or simplify model architecture to use fewer parameters.\n",
    "\n",
    "**Problem:** Dimensions mismatch in linear layer **Solution:** Calculate the exact output size after convolution and pooling layers to set the correct input size for your first linear layer.\n",
    "\n",
    "**Problem:** Training loss doesn't decrease **Solution:** Verify optimizer setup, try a different learning rate, or check for issues in your model architecture.\n",
    "\n",
    "## üîë Key Points\n",
    "- Convolutional layers extract spatial features from images, making them ideal for computer vision tasks\n",
    "- Normalization and preprocessing significantly impact CNN performance and training stability\n",
    "- Model architecture design requires balancing depth, parameter count, and computational requirements\n",
    "- Evaluating models requires both quantitative metrics and qualitative analysis of predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce10e1e",
   "metadata": {},
   "source": [
    "## üíª Reference Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e86edc",
   "metadata": {},
   "source": [
    "<details>\n",
    "\n",
    "<summary><strong>Click HERE to see a reference solution</strong></summary>    \n",
    "    \n",
    "```python\n",
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Task 1: Loading and preparing the dataset\n",
    "# Define transformations for image preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 training and test datasets\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "# Define classes for CIFAR-10\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Function to display images\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # Unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Get random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Show images\n",
    "print('Sample training images:')\n",
    "imshow(torchvision.utils.make_grid(images[:6]))\n",
    "print('Labels:', ' '.join('%5s' % classes[labels[j]] for j in range(6)))\n",
    "\n",
    "# Task 2: Designing the CNN Architecture\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # First convolutional layer\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)  # (32x32x3) -> (32x32x32)\n",
    "        # First pooling layer \n",
    "        self.pool1 = nn.MaxPool2d(2, 2)  # (32x32x32) -> (16x16x32)\n",
    "        # Second convolutional layer\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)  # (16x16x32) -> (16x16x64)\n",
    "        # Second pooling layer\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)  # (16x16x64) -> (8x8x64)\n",
    "        # Third convolutional layer\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)  # (8x8x64) -> (8x8x128)\n",
    "        # Third pooling layer\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)  # (8x8x128) -> (4x4x128)\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)  # Flattened output to 512\n",
    "        self.fc2 = nn.Linear(512, 10)  # 10 output classes\n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply conv layers with ReLU and pooling\n",
    "        x = self.pool1(torch.relu(self.conv1(x)))\n",
    "        x = self.pool2(torch.relu(self.conv2(x)))\n",
    "        x = self.pool3(torch.relu(self.conv3(x)))\n",
    "        # Flatten the output for the fully connected layer\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        # Apply dropout for regularization\n",
    "        x = self.dropout(x)\n",
    "        # Apply fully connected layers with ReLU\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create the model\n",
    "model = CNN()\n",
    "print(model)\n",
    "\n",
    "# Test the model with a batch\n",
    "sample_batch = next(iter(trainloader))[0]\n",
    "output = model(sample_batch)\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "\n",
    "# Task 3: Training the CNN Model\n",
    "# Choose loss function and optimizer\n",
    "# CrossEntropyLoss is suitable for multi-class classification, \n",
    "# as it combines Softmax and Negative Log Likelihood Loss.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "# Define learning rate\n",
    "LEARNING_RATE = 0.001  \n",
    "    \n",
    "# Define the optimizer # Adam is an adaptive learning rate optimizer, \n",
    "# generally a good default choice. # It updates model parameters based on # gradients. \n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on: {device}\")\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 10\n",
    "train_losses = []\n",
    "\n",
    "# Training loop\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get inputs and labels, and move them to the device\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Print statistics every 100 mini-batches\n",
    "        if i % 100 == 99:\n",
    "            print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}')\n",
    "            train_losses.append(running_loss / 100)\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Training complete!')\n",
    "\n",
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('100s of Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "# Task 4: Evaluating Model Performance\n",
    "# Evaluate on test set\n",
    "model.eval()  # Set to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Class-wise accuracy\n",
    "class_correct = [0] * 10\n",
    "class_total = [0] * 10\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Class accuracy\n",
    "        for i in range(labels.size(0)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += (predicted[i] == label).item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "# Overall accuracy\n",
    "print(f'Accuracy on 10,000 test images: {100 * correct / total:.2f}%')\n",
    "\n",
    "# Per-class accuracy\n",
    "for i in range(10):\n",
    "    print(f'Accuracy of {classes[i]}: {100 * class_correct[i] / class_total[i]:.2f}%')\n",
    "\n",
    "# Visualize some predictions\n",
    "model.eval()\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "# Get predictions\n",
    "outputs = model(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Move images and predictions back to CPU for visualization\n",
    "images = images.cpu()\n",
    "predicted = predicted.cpu()\n",
    "labels = labels.cpu()\n",
    "\n",
    "# Show images with predictions\n",
    "plt.figure(figsize=(15, 8))\n",
    "for i in range(12):\n",
    "    plt.subplot(3, 4, i+1)\n",
    "    imshow_single = lambda img: plt.imshow(np.transpose(img.numpy() / 2 + 0.5, (1, 2, 0)))\n",
    "    imshow_single(images[i])\n",
    "    color = 'green' if predicted[i] == labels[i] else 'red'\n",
    "    plt.title(f'Pred: {classes[predicted[i]]}\\nTrue: {classes[labels[i]]}', color=color)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'cifar10_cnn.pth')\n",
    "print(\"Model saved as 'cifar10_cnn.pth'\")\n",
    "```    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
