{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Character-Level RNN and Hidden State Evolution"
      ],
      "metadata": {
        "id": "TYxoVLYA3lhx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Setting Up the RNN Environment\n"
      ],
      "metadata": {
        "id": "0IvATiNA3lYd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trHEF5yh3SpQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Set a seed for reproducibility of results, especially the random weight initialization\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# Define a basic RNN\n",
        "class CharRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(CharRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        # batch_first=True means input/output tensors are (batch, seq, feature)\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        # x shape: (batch_size, seq_len, input_size)\n",
        "        # hidden shape: (num_layers * num_directions, batch_size, hidden_size)\n",
        "\n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        # out shape: (batch_size, seq_len, hidden_size) after RNN\n",
        "\n",
        "        # Pass RNN output through the fully connected layer\n",
        "        # self.fc expects input of shape (..., hidden_size) and applies to the last dimension\n",
        "        out = self.fc(out)\n",
        "        # out shape: (batch_size, seq_len, output_size)\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        # Initialize hidden state with zeros\n",
        "        # Shape: (num_layers * num_directions, batch_size, hidden_size)\n",
        "        # For nn.RNN default: num_layers=1, num_directions=1\n",
        "        return torch.zeros(1, batch_size, self.hidden_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Demonstrating Character-Level Input Handling\n"
      ],
      "metadata": {
        "id": "2AecybH334-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Character to index mapping and vocabulary\n",
        "char2idx = {'a': 0, 'b': 1, 'c': 2}\n",
        "idx2char = {v: k for k, v in char2idx.items()}\n",
        "vocab_size = len(char2idx)\n",
        "\n",
        "# Sample input sequence\n",
        "input_seq = 'abc'\n",
        "\n",
        "# Convert characters to numerical indices\n",
        "input_indices = [char2idx[c] for c in input_seq]\n",
        "\n",
        "# Prepare input tensor for the RNN\n",
        "# Shape: (batch_size, seq_len, input_size)\n",
        "# - batch_size = 1: We process one sequence at a time.\n",
        "# - seq_len = len(input_seq): Length of our input sequence.\n",
        "# - input_size = 1: We use the character's index directly as its feature.\n",
        "#   (A common alternative is one-hot encoding, where input_size would be vocab_size)\n",
        "input_tensor = torch.tensor(input_indices, dtype=torch.float32).view(1, len(input_seq), 1)\n",
        "\n",
        "print(f\"Input sequence: '{input_seq}'\")\n",
        "print(f\"Character indices: {input_indices}\")\n",
        "print(f\"Input tensor shape: {input_tensor.shape}\")\n",
        "print(f\"Input tensor preview: {input_tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2xOIt3W35Ou",
        "outputId": "5024d5f5-ec7e-4050-a645-ca4c1f6a9a5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input sequence: 'abc'\n",
            "Character indices: [0, 1, 2]\n",
            "Input tensor shape: torch.Size([1, 3, 1])\n",
            "Input tensor preview: tensor([[[0.],\n",
            "         [1.],\n",
            "         [2.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Running the Forward Pass and Observing Hidden State Evolution\n"
      ],
      "metadata": {
        "id": "8BG5R-wj39-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model parameters\n",
        "rnn_input_size = 1     # Corresponds to input_tensor's feature dimension\n",
        "rnn_hidden_size = 5    # Arbitrary size for the hidden layer\n",
        "rnn_output_size = vocab_size # Network predicts one of the characters in vocab\n",
        "\n",
        "# Instantiate the model\n",
        "model = CharRNN(input_size=rnn_input_size, hidden_size=rnn_hidden_size, output_size=rnn_output_size)\n",
        "\n",
        "# Initialize the hidden state for a batch_size of 1\n",
        "# batch_size for hidden state should match batch_size of input tensor\n",
        "hidden = model.init_hidden(batch_size=1)\n",
        "\n",
        "print(f\"\\nModel: CharRNN(input_size={rnn_input_size}, hidden_size={rnn_hidden_size}, output_size={rnn_output_size})\")\n",
        "print(f\"Initial hidden state shape: {hidden.shape}\")\n",
        "print(f\"\\nProcessing sequence '{input_seq}' step-by-step:\\n\")\n",
        "\n",
        "# Loop through each character in the input sequence\n",
        "for i in range(input_tensor.size(1)):  # input_tensor.size(1) is seq_len\n",
        "    # Get the current character's tensor slice\n",
        "    # Shape: (batch_size, 1, input_size) which is (1, 1, 1) for this iteration\n",
        "    current_char_tensor = input_tensor[:, i:i+1, :]\n",
        "\n",
        "    # Perform a forward pass through the model\n",
        "    # - output: Logits for the next character prediction based on current input and hidden state.\n",
        "    #           Shape: (batch_size, 1, output_size) e.g., (1, 1, vocab_size)\n",
        "    # - hidden: Updated hidden state after processing the current character.\n",
        "    #           Shape: (1, batch_size, hidden_size) e.g., (1, 1, rnn_hidden_size)\n",
        "    output, hidden = model(current_char_tensor, hidden)\n",
        "\n",
        "    current_char = idx2char[input_indices[i]]\n",
        "    print(f\"Step {i+1}: Input Char '{current_char}'\")\n",
        "    print(f\"  Tensor: {current_char_tensor.item():.1f}\") # Display the single float value from the (1,1,1) tensor\n",
        "    # .detach() is used to remove the tensor from gradient tracking for printing\n",
        "    print(f\"  Hidden State: {hidden.detach().numpy().squeeze()}\") # .squeeze() to make it more readable\n",
        "    print(f\"  Output Logits (for next char): {output.detach().numpy().squeeze()}\\n\")\n",
        "\n",
        "# After the loop, 'output' holds the logits from processing the *last* character ('c'),\n",
        "# and 'hidden' is the final hidden state."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZhvMs4y3-VS",
        "outputId": "fe481af0-0105-46e4-b65d-e8a2b32078b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model: CharRNN(input_size=1, hidden_size=5, output_size=3)\n",
            "Initial hidden state shape: torch.Size([1, 1, 5])\n",
            "\n",
            "Processing sequence 'abc' step-by-step:\n",
            "\n",
            "Step 1: Input Char 'a'\n",
            "  Tensor: 0.0\n",
            "  Hidden State: [-0.5321693   0.12468402  0.09426841 -0.00631211 -0.09539835]\n",
            "  Output Logits (for next char): [-0.26382893  0.26871914 -0.4557599 ]\n",
            "\n",
            "Step 2: Input Char 'b'\n",
            "  Tensor: 1.0\n",
            "  Hidden State: [-0.5642533   0.38454792 -0.21128117 -0.36226147 -0.26284283]\n",
            "  Output Logits (for next char): [-0.14454445  0.34262192 -0.4753492 ]\n",
            "\n",
            "Step 3: Input Char 'c'\n",
            "  Tensor: 2.0\n",
            "  Hidden State: [-0.642596    0.7131781  -0.44515392 -0.60197914 -0.09150449]\n",
            "  Output Logits (for next char): [-0.19470005  0.43686768 -0.35626823]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Visualizing and Interpreting Output Predictions\n"
      ],
      "metadata": {
        "id": "92ijpZ3d4CK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The 'output' variable from the loop contains the logits after processing the last character.\n",
        "# Its shape is (batch_size, 1, output_size).\n",
        "\n",
        "# Predict the index of the next character by finding the max logit.\n",
        "# torch.argmax operates on the specified dimension (dim=2, which is the output_size dimension).\n",
        "predicted_index_tensor = torch.argmax(output, dim=2) # Shape: (batch_size, 1) e.g., (1,1)\n",
        "\n",
        "# .item() converts a single-element tensor to a Python number.\n",
        "predicted_index = predicted_index_tensor.item()\n",
        "\n",
        "# Convert the predicted index back to a character.\n",
        "predicted_char = idx2char[predicted_index]\n",
        "\n",
        "print(f\"--- Final Prediction ---\")\n",
        "print(f\"After processing the full sequence '{input_seq}', the final output logits are: {output.detach().numpy().squeeze()}\")\n",
        "print(f\"The model predicts the next character could be: '{predicted_char}' (Index: {predicted_index})\")\n",
        "print(\"\\nNote: This prediction is from an untrained model with random initial weights.\")\n",
        "print(\"The purpose is to show the *mechanism* of prediction and hidden state flow, not to demonstrate learned behavior.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWK6KLK84CdF",
        "outputId": "bc049b7e-f3c2-46fc-dec3-6f25ac0778a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Final Prediction ---\n",
            "After processing the full sequence 'abc', the final output logits are: [-0.19470005  0.43686768 -0.35626823]\n",
            "The model predicts the next character could be: 'b' (Index: 1)\n",
            "\n",
            "Note: This prediction is from an untrained model with random initial weights.\n",
            "The purpose is to show the *mechanism* of prediction and hidden state flow, not to demonstrate learned behavior.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T29JAL0Gd7-v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}