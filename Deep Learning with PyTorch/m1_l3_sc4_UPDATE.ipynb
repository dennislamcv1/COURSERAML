{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Controlling Back Propagation of Gradients\n"
      ],
      "metadata": {
        "id": "QYDCQBcNelFH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 0: Imports\n"
      ],
      "metadata": {
        "id": "-yuIjuQieoPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!!pip install torchviz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Sp35d_XYVrZ",
        "outputId": "d3cfc6b1-ccd1-4536-d1fa-0dff75f14f9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Requirement already satisfied: torchviz in /usr/local/lib/python3.11/dist-packages (0.0.3)',\n",
              " 'Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torchviz) (2.6.0+cu124)',\n",
              " 'Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from torchviz) (0.20.3)',\n",
              " 'Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.18.0)',\n",
              " 'Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (4.13.2)',\n",
              " 'Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.4.2)',\n",
              " 'Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.1.6)',\n",
              " 'Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (2025.3.2)',\n",
              " 'Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.4.127)',\n",
              " 'Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.4.127)',\n",
              " 'Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.4.127)',\n",
              " 'Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (9.1.0.70)',\n",
              " 'Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.4.5.8)',\n",
              " 'Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (11.2.1.3)',\n",
              " 'Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (10.3.5.147)',\n",
              " 'Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (11.6.1.9)',\n",
              " 'Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.3.1.170)',\n",
              " 'Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (0.6.2)',\n",
              " 'Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (2.21.5)',\n",
              " 'Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.4.127)',\n",
              " 'Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.4.127)',\n",
              " 'Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.2.0)',\n",
              " 'Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (1.13.1)',\n",
              " 'Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torchviz) (1.3.0)',\n",
              " 'Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torchviz) (3.0.2)']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rRPtIi6b9M0",
        "outputId": "3504c35b-bd7d-4c7b-aee1-c8b5631e214d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchviz in /usr/local/lib/python3.11/dist-packages (0.0.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torchviz) (2.6.0+cu124)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from torchviz) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torchviz) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torchviz) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchviz import make_dot\n",
        "import graphviz\n",
        "\n",
        "# To visualize the computation graph, you need to install torchviz:\n",
        "!pip install torchviz\n",
        "try:\n",
        "    from torchviz import make_dot\n",
        "    has_torchviz = True\n",
        "except ImportError:\n",
        "    has_torchviz = False\n",
        "    print(\"torchviz is not installed.  Install it with 'pip install torchviz' to see computation graphs.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Using `.detach()` to Stop Gradient Flow"
      ],
      "metadata": {
        "id": "7YMDD_jFeswe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchviz import make_dot\n",
        "import graphviz\n",
        "\n",
        "# Initial tensor requiring gradients\n",
        "a = torch.tensor([2.0], requires_grad=True)\n",
        "print(f\"Original tensor a: {a}\")\n",
        "\n",
        "# First operation connected to 'a'\n",
        "b = a * 3\n",
        "print(f\"Tensor b (a * 3): {b}\")\n",
        "\n",
        "print(\"\\n--- Visualizing Graph BEFORE detach ---\")\n",
        "dot_before = make_dot(b, params={'a': a})\n",
        "dot_before.attr(rankdir='LR')\n",
        "display(dot_before)\n",
        "print(\"Computation graph before detach (displayed above)\")\n",
        "\n",
        "\n",
        "# Detach 'b' to create 'c'.\n",
        "c = b.detach()\n",
        "print(f\"\\nTensor c (b.detach()): {c}, requires_grad for c: {c.requires_grad}\") # ADD \\n for better spacing\n",
        "\n",
        "# Note: 'c' could have its own requires_grad set to True (e.g., c.requires_grad_(True))\n",
        "# for subsequent operations, but gradients would only flow back to 'c', not through to 'a'.\n",
        "# This is not done here to keep the example focused.\n",
        "\n",
        "# Operation using the detached tensor 'c'\n",
        "out1 = c * 2\n",
        "print(f\"out1 (c * 2): {out1}\")\n",
        "\n",
        "# Operation using the original tensor 'b' (still connected to 'a')\n",
        "out2 = b * 4\n",
        "print(f\"out2 (b * 4): {out2}\")\n",
        "\n",
        "# Combine outputs for the final 'loss'\n",
        "L = out1 + out2\n",
        "print(f\"L (out1 + out2): {L}\")\n",
        "\n",
        "# Visualize the graph *after* detach\n",
        "print(\"\\n--- Visualizing Graph AFTER detach ---\")\n",
        "dot_after = make_dot(L, params={'a': a})\n",
        "dot_after.attr(rankdir='LR')\n",
        "display(dot_after)\n",
        "print(\"Computation graph after detach (displayed above)\")\n",
        "\n",
        "# Backpropagate\n",
        "L.backward()\n",
        "\n",
        "# Check the gradient of 'a'\n",
        "print(f\"\\nGradient of a (a.grad): {a.grad}\") # ADD \\n for better spacing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "Tjn7q-UNa3Hd",
        "outputId": "1785ae98-b65e-4125-d663-869e3fc47f0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor a: tensor([2.], requires_grad=True)\n",
            "Tensor b (a * 3): tensor([6.], grad_fn=<MulBackward0>)\n",
            "\n",
            "--- Visualizing Graph BEFORE detach ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"414pt\" height=\"39pt\"\n viewBox=\"0.00 0.00 414.00 39.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 35)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-35 410,-35 410,4 -4,4\"/>\n<!-- 132914146082544 -->\n<g id=\"node1\" class=\"node\">\n<title>132914146082544</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"406,-31 352,-31 352,0 406,0 406,-31\"/>\n<text text-anchor=\"middle\" x=\"379\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n</g>\n<!-- 132914193535264 -->\n<g id=\"node2\" class=\"node\">\n<title>132914193535264</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"316,-25 227,-25 227,-6 316,-6 316,-25\"/>\n<text text-anchor=\"middle\" x=\"271.5\" y=\"-13\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n</g>\n<!-- 132914193535264&#45;&gt;132914146082544 -->\n<g id=\"edge3\" class=\"edge\">\n<title>132914193535264&#45;&gt;132914146082544</title>\n<path fill=\"none\" stroke=\"black\" d=\"M316.02,-15.5C324.56,-15.5 333.43,-15.5 341.71,-15.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"341.8,-19 351.8,-15.5 341.8,-12 341.8,-19\"/>\n</g>\n<!-- 132914193535744 -->\n<g id=\"node3\" class=\"node\">\n<title>132914193535744</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"191,-25 90,-25 90,-6 191,-6 191,-25\"/>\n<text text-anchor=\"middle\" x=\"140.5\" y=\"-13\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 132914193535744&#45;&gt;132914193535264 -->\n<g id=\"edge1\" class=\"edge\">\n<title>132914193535744&#45;&gt;132914193535264</title>\n<path fill=\"none\" stroke=\"black\" d=\"M191.01,-15.5C199.39,-15.5 208.13,-15.5 216.62,-15.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"216.82,-19 226.82,-15.5 216.82,-12 216.82,-19\"/>\n</g>\n<!-- 132914145289104 -->\n<g id=\"node4\" class=\"node\">\n<title>132914145289104</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"54,-30.5 0,-30.5 0,-0.5 54,-0.5 54,-30.5\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-18.5\" font-family=\"monospace\" font-size=\"10.00\">a</text>\n<text text-anchor=\"middle\" x=\"27\" y=\"-7.5\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n</g>\n<!-- 132914145289104&#45;&gt;132914193535744 -->\n<g id=\"edge2\" class=\"edge\">\n<title>132914145289104&#45;&gt;132914193535744</title>\n<path fill=\"none\" stroke=\"black\" d=\"M54.14,-15.5C61.91,-15.5 70.75,-15.5 79.73,-15.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"79.88,-19 89.88,-15.5 79.88,-12 79.88,-19\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x78e27e56e2d0>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computation graph before detach (displayed above)\n",
            "\n",
            "Tensor c (b.detach()): tensor([6.]), requires_grad for c: False\n",
            "out1 (c * 2): tensor([12.])\n",
            "out2 (b * 4): tensor([24.], grad_fn=<MulBackward0>)\n",
            "L (out1 + out2): tensor([36.], grad_fn=<AddBackward0>)\n",
            "\n",
            "--- Visualizing Graph AFTER detach ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"664pt\" height=\"39pt\"\n viewBox=\"0.00 0.00 664.00 39.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 35)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-35 660,-35 660,4 -4,4\"/>\n<!-- 132914193388016 -->\n<g id=\"node1\" class=\"node\">\n<title>132914193388016</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"656,-31 602,-31 602,0 656,0 656,-31\"/>\n<text text-anchor=\"middle\" x=\"629\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n</g>\n<!-- 132914193530992 -->\n<g id=\"node2\" class=\"node\">\n<title>132914193530992</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"566,-25 477,-25 477,-6 566,-6 566,-25\"/>\n<text text-anchor=\"middle\" x=\"521.5\" y=\"-13\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 132914193530992&#45;&gt;132914193388016 -->\n<g id=\"edge5\" class=\"edge\">\n<title>132914193530992&#45;&gt;132914193388016</title>\n<path fill=\"none\" stroke=\"black\" d=\"M566.02,-15.5C574.56,-15.5 583.43,-15.5 591.71,-15.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"591.8,-19 601.8,-15.5 591.8,-12 591.8,-19\"/>\n</g>\n<!-- 132914193547168 -->\n<g id=\"node3\" class=\"node\">\n<title>132914193547168</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"441,-25 352,-25 352,-6 441,-6 441,-25\"/>\n<text text-anchor=\"middle\" x=\"396.5\" y=\"-13\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n</g>\n<!-- 132914193547168&#45;&gt;132914193530992 -->\n<g id=\"edge1\" class=\"edge\">\n<title>132914193547168&#45;&gt;132914193530992</title>\n<path fill=\"none\" stroke=\"black\" d=\"M441.21,-15.5C449.46,-15.5 458.17,-15.5 466.69,-15.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"466.93,-19 476.93,-15.5 466.93,-12 466.93,-19\"/>\n</g>\n<!-- 132914193535264 -->\n<g id=\"node4\" class=\"node\">\n<title>132914193535264</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"316,-25 227,-25 227,-6 316,-6 316,-25\"/>\n<text text-anchor=\"middle\" x=\"271.5\" y=\"-13\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n</g>\n<!-- 132914193535264&#45;&gt;132914193547168 -->\n<g id=\"edge2\" class=\"edge\">\n<title>132914193535264&#45;&gt;132914193547168</title>\n<path fill=\"none\" stroke=\"black\" d=\"M316.21,-15.5C324.46,-15.5 333.17,-15.5 341.69,-15.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"341.93,-19 351.93,-15.5 341.93,-12 341.93,-19\"/>\n</g>\n<!-- 132914193535744 -->\n<g id=\"node5\" class=\"node\">\n<title>132914193535744</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"191,-25 90,-25 90,-6 191,-6 191,-25\"/>\n<text text-anchor=\"middle\" x=\"140.5\" y=\"-13\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 132914193535744&#45;&gt;132914193535264 -->\n<g id=\"edge3\" class=\"edge\">\n<title>132914193535744&#45;&gt;132914193535264</title>\n<path fill=\"none\" stroke=\"black\" d=\"M191.01,-15.5C199.39,-15.5 208.13,-15.5 216.62,-15.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"216.82,-19 226.82,-15.5 216.82,-12 216.82,-19\"/>\n</g>\n<!-- 132914145289104 -->\n<g id=\"node6\" class=\"node\">\n<title>132914145289104</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"54,-30.5 0,-30.5 0,-0.5 54,-0.5 54,-30.5\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-18.5\" font-family=\"monospace\" font-size=\"10.00\">a</text>\n<text text-anchor=\"middle\" x=\"27\" y=\"-7.5\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n</g>\n<!-- 132914145289104&#45;&gt;132914193535744 -->\n<g id=\"edge4\" class=\"edge\">\n<title>132914145289104&#45;&gt;132914193535744</title>\n<path fill=\"none\" stroke=\"black\" d=\"M54.14,-15.5C61.91,-15.5 70.75,-15.5 79.73,-15.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"79.88,-19 89.88,-15.5 79.88,-12 79.88,-19\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x78e27c6c0d90>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computation graph after detach (displayed above)\n",
            "\n",
            "Gradient of a (a.grad): tensor([12.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: \"Freezing\" Parameters with `requires_grad = False`\n"
      ],
      "metadata": {
        "id": "TfvWbmcBe7tx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Create a simple linear model\n",
        "# This model has two learnable parts: 'weight' and 'bias'.\n",
        "# By default, PyTorch knows we want to train (learn) these,\n",
        "# so it sets their 'requires_grad' property to True.\n",
        "model = nn.Linear(in_features=3, out_features=2)\n",
        "print(\"Initial model parameters:\")\n",
        "print(f\"  model.weight: {model.weight.data}\")\n",
        "print(f\"  model.bias: {model.bias.data}\\n\")\n",
        "\n",
        "# Confirm both weight and bias are set to be updated initially\n",
        "print(f\"Original requires_grad for model.weight: {model.weight.requires_grad}\") # True, meaning it will be updated\n",
        "print(f\"Original requires_grad for model.bias: {model.bias.requires_grad}\\n\")     # True, meaning it will be updated\n",
        "\n",
        "# --- FREEZING A PARAMETER ---\n",
        "# We want to \"freeze\" the 'weight' parameter.\n",
        "# This means we DO NOT want its value to change during training.\n",
        "# Why freeze? Imagine using a pre-trained model; you might want to keep its\n",
        "# learned features fixed and only train new layers.\n",
        "model.weight.requires_grad = False\n",
        "# By setting requires_grad to False, we tell PyTorch:\n",
        "# 1. DO NOT calculate gradients for 'model.weight' during backpropagation.\n",
        "# 2. As a result, the optimizer will skip updating 'model.weight'.\n",
        "print(f\"New requires_grad for model.weight: {model.weight.requires_grad}\") # Now False (frozen)\n",
        "print(f\"requires_grad for model.bias remains: {model.bias.requires_grad}\\n\") # Still True (will be updated)\n",
        "\n",
        "# Store original parameter values to check for changes later\n",
        "original_weight = model.weight.data.clone()\n",
        "original_bias = model.bias.data.clone()\n",
        "\n",
        "# Dummy input and target data\n",
        "dummy_input = torch.randn(4, 3)\n",
        "dummy_target = torch.randn(4, 2)\n",
        "\n",
        "# Optimizer: This is what adjusts our model's learnable parameters.\n",
        "# It receives ALL parameters from the model.\n",
        "# Crucially, the optimizer will only update parameters that have gradients computed\n",
        "# (i.e., those where 'requires_grad' is True and thus a gradient is available).\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "# --- One step of \"training\" ---\n",
        "optimizer.zero_grad()       # Clear any old gradients\n",
        "output = model(dummy_input) # Pass data through the model (forward pass)\n",
        "loss = nn.MSELoss()(output, dummy_target) # Calculate how \"wrong\" our model is (loss)\n",
        "loss.backward()             # Compute gradients (backward pass)\n",
        "                            # PyTorch calculates how much each 'requires_grad=True'\n",
        "                            # parameter needs to change to reduce the loss.\n",
        "                            # Since 'model.weight.requires_grad' is False, NO gradient\n",
        "                            # is computed for it. 'model.bias' gets a gradient.\n",
        "\n",
        "# Check the computed gradients\n",
        "print(\"Gradients after backward pass:\")\n",
        "# No gradient for weight because it was frozen (requires_grad=False)\n",
        "print(f\"  Gradient for model.weight: {model.weight.grad}\")\n",
        "# A gradient exists for bias because it's still trainable (requires_grad=True)\n",
        "print(f\"  Gradient for model.bias: {model.bias.grad}\\n\")\n",
        "\n",
        "optimizer.step()            # Optimizer uses the gradients to update parameters.\n",
        "                            # It only updates parameters for which gradients were computed.\n",
        "\n",
        "# Check if parameters actually changed\n",
        "print(\"Parameters after optimizer step:\")\n",
        "print(f\"  model.weight: {model.weight.data}\")\n",
        "print(f\"  model.bias: {model.bias.data}\\n\")\n",
        "\n",
        "weight_updated = not torch.equal(model.weight.data, original_weight)\n",
        "bias_updated = not torch.equal(model.bias.data, original_bias)\n",
        "\n",
        "print(f\"Was model.weight updated? {weight_updated}\") # Expected: False (it was frozen!)\n",
        "print(f\"Was model.bias updated? {bias_updated}\")     # Expected: True (it was trainable!)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjc_-eRVfAX8",
        "outputId": "9919894b-fa03-4626-8b6e-fad54b2bfdd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial model parameters:\n",
            "  model.weight: tensor([[ 0.3181,  0.4520, -0.5551],\n",
            "        [-0.0733,  0.3091, -0.4354]])\n",
            "  model.bias: tensor([-0.2679, -0.3763])\n",
            "\n",
            "Original requires_grad for model.weight: True\n",
            "Original requires_grad for model.bias: True\n",
            "\n",
            "New requires_grad for model.weight: False\n",
            "requires_grad for model.bias remains: True\n",
            "\n",
            "Gradients after backward pass:\n",
            "  Gradient for model.weight: None\n",
            "  Gradient for model.bias: tensor([0.5126, 0.2573])\n",
            "\n",
            "Parameters after optimizer step:\n",
            "  model.weight: tensor([[ 0.3181,  0.4520, -0.5551],\n",
            "        [-0.0733,  0.3091, -0.4354]])\n",
            "  model.bias: tensor([-0.3192, -0.4020])\n",
            "\n",
            "Was model.weight updated? False\n",
            "Was model.bias updated? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tBkAiMY9Rzsk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}