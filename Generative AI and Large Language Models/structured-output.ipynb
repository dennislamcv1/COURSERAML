{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üë©‚Äçüíª **Prompt LLMs for Structured Output + Simulated Function Use**\n",
    "\n",
    "**Time Estimate:** 45 minutes\n",
    "\n",
    "## üìã **Overview**\n",
    "\n",
    "This activity focuses on enhancing your ability to craft effective prompts for generating structured outputs such as JSON/XML, and simulating logical processes with Large Language Models (LLMs). These skills are vital for developing applications that require precise data manipulation, common in fields such as software development and data analysis.\n",
    "\n",
    "In this activity, you will create and refine prompts to guide LLMs for predictable outputs, and simulate function calls to ensure practical data logic using free, accessible models.\n",
    "\n",
    "## üéØ **Learning Outcomes**\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "- Design prompts that yield structured JSON/XML outputs.\n",
    "- Simulate logical operations using LLM-generated outputs.\n",
    "- Refine prompt engineering skills to ensure accuracy and consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Setup and Basic JSON Generation [15 minutes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Setup a free local LLM and create helper functions for JSON parsing.\n",
    "2. Test basic structured output generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1\n",
    "# your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîç **Practice**\n",
    "\n",
    "Test your setup with a simple prompt. Consider:\n",
    "\n",
    "- How well the model generates structured output.\n",
    "- The quality of JSON formatting from smaller models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ **Success Checklist**\n",
    "\n",
    "- Model loads without errors.\n",
    "- JSON parsing helper function works correctly.\n",
    "- Basic structured output generation tested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Key Points**\n",
    "\n",
    "- Smaller models require more explicit prompting for structured output.\n",
    "- JSON parsing tools help handle imperfect model outputs.\n",
    "- Clear examples in prompts improve consistency.\n",
    "\n",
    "‚ùó **Common Mistakes to Avoid**\n",
    "\n",
    "- Using high temperature for structured tasks (use 0.1-0.3 instead).\n",
    "- Not providing exact format examples in prompts.\n",
    "- Forgetting to validate generated JSON structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Travel Itinerary JSON Generation [15 minutes]\n",
    "Create prompts that generate well-structured JSON for travel itineraries.\n",
    "1. Design a prompt with exact JSON structure examples.\n",
    "2. Generate travel itineraries for multiple destinations.\n",
    "3. Validate the consistency of generated JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2\n",
    "# your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîç **Practice**\n",
    "\n",
    "Test different destinations and analyze the quality of generated content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ **Success Checklist**\n",
    "\n",
    "- JSON structure matches expected format consistently.\n",
    "- All required fields are present in generated outputs.\n",
    "- Content is relevant and realistic for each destination.\n",
    "\n",
    "üí° **Key Points**\n",
    "\n",
    "- Providing exact JSON structure examples improves output consistency.\n",
    "- Lower temperature settings help maintain structure.\n",
    "- Multiple examples in prompts can improve format adherence.\n",
    "\n",
    "‚ùó **Common Mistakes to Avoid**\n",
    "\n",
    "- Vague structure specifications in prompts.\n",
    "- Inconsistent field naming across examples.\n",
    "- Not testing with diverse input variations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Function Simulation - Order Calculations [15 minutes]\n",
    "Simulate mathematical function logic using natural language prompts.\n",
    "1. Create step-by-step calculation prompts.\n",
    "2. Test order total calculations with tax and shipping.\n",
    "3. Extract and verify numerical results from LLM outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3\n",
    "# your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ **Success Checklist**\n",
    "\n",
    "- Calculation steps are logically sequenced and clear.\n",
    "- Mathematical operations are performed accurately.\n",
    "- Final totals can be extracted and verified against actual calculations.\n",
    "\n",
    "üí° **Key Points**\n",
    "\n",
    "- Very low temperature (0.1) improves mathematical accuracy.\n",
    "- Step-by-step examples help guide logical processes.\n",
    "- Always verify LLM calculations with actual mathematical computation.\n",
    "\n",
    "‚ùó **Common Mistakes to Avoid**\n",
    "\n",
    "- Using high temperature for mathematical tasks.\n",
    "- Not providing clear calculation examples.\n",
    "- Trusting LLM math without verification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üöÄ **Next Steps**\n",
    "\n",
    "In the next module, you will learn how to extend these structured output skills to more complex applications like API integration, database operations, and multi-step workflow automation. This builds on the concepts of prompt engineering and structured data generation to enhance your ability to create robust AI-powered applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíª Exemplar Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary><strong>Click HERE to see an exemplar solution</strong></summary>\n",
    "\n",
    "### Task 1 Solution\n",
    "    \n",
    "```python\n",
    "# Setup free local LLM\n",
    "model_name = \"gpt2\"\n",
    "generator = pipeline('text-generation', \n",
    "                    model=model_name, \n",
    "                    max_length=300,\n",
    "                    pad_token_id=50256)\n",
    "\n",
    "def clean_and_parse_json(text):\n",
    "    \"\"\"Helper function to extract and clean JSON from model output\"\"\"\n",
    "    json_match = re.search(r'\\{[^{}]*\\}', text, re.DOTALL)\n",
    "    if json_match:\n",
    "        json_str = json_match.group()\n",
    "        try:\n",
    "            return json.loads(json_str)\n",
    "        except json.JSONDecodeError:\n",
    "            return {\"error\": \"Could not parse JSON\", \"raw\": json_str}\n",
    "    return {\"error\": \"No JSON found\", \"raw\": text}\n",
    "\n",
    "print(\"‚úÖ Model and helper functions ready\")\n",
    "\n",
    "# Test basic JSON generation\n",
    "test_prompt = \"\"\"Create a JSON object with name and age:\n",
    "{\n",
    "  \"name\": \"Alice\",\n",
    "  \"age\": 25\n",
    "}\n",
    "\n",
    "Create similar JSON for Bob, age 30:\n",
    "{\"\"\"\n",
    "\n",
    "response = generator(test_prompt, max_length=50, temperature=0.2, do_sample=True)\n",
    "generated = response[0]['generated_text'][len(test_prompt):]\n",
    "result = clean_and_parse_json(\"{\" + generated)\n",
    "print(\"Test result:\", result)\n",
    "```\n",
    "\n",
    "### Task 2 Solution\n",
    "    \n",
    "```python\n",
    "def generate_travel_itinerary(destination, days=3):\n",
    "    \"\"\"Generate structured travel itinerary JSON\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"Create a travel itinerary in JSON format for {destination}. Follow this exact structure:\n",
    "\n",
    "{{\n",
    "  \"destination\": \"{destination}\",\n",
    "  \"duration_days\": {days},\n",
    "  \"departure_date\": \"2024-06-15\",\n",
    "  \"activities\": [\n",
    "    \"Visit landmarks\",\n",
    "    \"Try local cuisine\"\n",
    "  ],\n",
    "  \"accommodations\": \"Hotel\",\n",
    "  \"budget_estimate\": \"$500-1000\"\n",
    "}}\n",
    "\n",
    "Generate similar JSON for {destination}:\n",
    "{{\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = generator(prompt, \n",
    "                           max_length=len(prompt.split()) + 100,\n",
    "                           temperature=0.3,\n",
    "                           do_sample=True,\n",
    "                           pad_token_id=50256)\n",
    "        \n",
    "        generated_text = response[0]['generated_text']\n",
    "        generated_part = generated_text[len(prompt):]\n",
    "        json_content = \"{\" + generated_part\n",
    "        \n",
    "        return clean_and_parse_json(json_content)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e), \"destination\": destination}\n",
    "\n",
    "# Test with multiple destinations\n",
    "destinations = [\"Paris\", \"Tokyo\", \"New York\"]\n",
    "\n",
    "for dest in destinations:\n",
    "    print(f\"\\n=== {dest.upper()} ITINERARY ===\")\n",
    "    itinerary = generate_travel_itinerary(dest)\n",
    "    print(json.dumps(itinerary, indent=2))\n",
    "```\n",
    "\n",
    "### Task 3 Solution\n",
    "\n",
    "```python\n",
    "def simulate_order_calculation(items_list):\n",
    "    \"\"\"Simulate order total calculation using LLM\"\"\"\n",
    "    \n",
    "    items_text = \"\\n\".join([f\"- {item['name']}: ${item['price']} x {item['quantity']}\" \n",
    "                           for item in items_list])\n",
    "    \n",
    "    prompt = f\"\"\"Calculate the total cost step by step:\n",
    "\n",
    "Items:\n",
    "{items_text}\n",
    "\n",
    "Example:\n",
    "- Laptop: $800 x 2 = $1600\n",
    "- Mouse: $25 x 1 = $25\n",
    "Subtotal: $1600 + $25 = $1625\n",
    "Tax (8%): $1625 x 0.08 = $130\n",
    "Total: $1625 + $130 = $1755\n",
    "\n",
    "Calculate for items above:\n",
    "Calculation:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = generator(prompt,\n",
    "                           max_length=len(prompt.split()) + 80,\n",
    "                           temperature=0.1,\n",
    "                           do_sample=True,\n",
    "                           pad_token_id=50256)\n",
    "        \n",
    "        generated_text = response[0]['generated_text']\n",
    "        calculation = generated_text[len(prompt):].strip()\n",
    "        \n",
    "        # Extract total from calculation\n",
    "        total_match = re.search(r'Total:\\s*\\$?([0-9,]+\\.?[0-9]*)', calculation, re.IGNORECASE)\n",
    "        extracted_total = total_match.group(1) if total_match else \"Not found\"\n",
    "        \n",
    "        return {\n",
    "            \"calculation_steps\": calculation,\n",
    "            \"extracted_total\": extracted_total,\n",
    "            \"items\": items_list\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e), \"items\": items_list}\n",
    "\n",
    "# Test order calculation\n",
    "test_order = [\n",
    "    {\"name\": \"Coffee\", \"price\": 5.99, \"quantity\": 3},\n",
    "    {\"name\": \"Sandwich\", \"price\": 8.50, \"quantity\": 2}\n",
    "]\n",
    "\n",
    "print(\"=== ORDER CALCULATION SIMULATION ===\")\n",
    "result = simulate_order_calculation(test_order)\n",
    "\n",
    "if \"error\" not in result:\n",
    "    print(\"Items:\")\n",
    "    for item in result[\"items\"]:\n",
    "        print(f\"  {item['name']}: ${item['price']} x {item['quantity']}\")\n",
    "    print(f\"\\nLLM Calculation:\\n{result['calculation_steps']}\")\n",
    "    print(f\"\\nExtracted Total: ${result['extracted_total']}\")\n",
    "    \n",
    "    # Verify with actual calculation\n",
    "    actual_total = sum(item['price'] * item['quantity'] for item in test_order)\n",
    "    tax = actual_total * 0.08\n",
    "    final_total = actual_total + tax\n",
    "    print(f\"Actual Total (with 8% tax): ${final_total:.2f}\")\n",
    "else:\n",
    "    print(f\"Error: {result['error']}\")\n",
    "\n",
    "# Enhanced function simulation example\n",
    "def simulate_route_decision(routes_data):\n",
    "    \"\"\"Simulate route optimization decision-making\"\"\"\n",
    "    \n",
    "    routes_text = \"\\n\".join([\n",
    "        f\"Route {i+1}: {route['name']} - Distance: {route['distance']}km, \"\n",
    "        f\"Traffic: {route['traffic']}, Time: {route['time']}min, Cost: ${route['cost']}\"\n",
    "        for i, route in enumerate(routes_data)\n",
    "    ])\n",
    "    \n",
    "    prompt = f\"\"\"Choose the optimal route based on distance, traffic, time, and cost.\n",
    "\n",
    "Available Routes:\n",
    "{routes_text}\n",
    "\n",
    "Analysis:\n",
    "1. Distance comparison:\n",
    "2. Traffic impact:\n",
    "3. Time efficiency:\n",
    "4. Cost consideration:\n",
    "5. Overall recommendation:\n",
    "\n",
    "Decision:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = generator(prompt,\n",
    "                           max_length=len(prompt.split()) + 100,\n",
    "                           temperature=0.3,\n",
    "                           do_sample=True,\n",
    "                           pad_token_id=50256)\n",
    "        \n",
    "        generated_text = response[0]['generated_text']\n",
    "        decision = generated_text[len(prompt):].strip()\n",
    "        \n",
    "        # Extract recommended route\n",
    "        route_match = re.search(r'Route\\s+(\\d+)', decision, re.IGNORECASE)\n",
    "        recommended_route = route_match.group(1) if route_match else \"Not specified\"\n",
    "        \n",
    "        return {\n",
    "            \"analysis\": decision,\n",
    "            \"recommended_route\": recommended_route,\n",
    "            \"routes\": routes_data\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e), \"routes\": routes_data}\n",
    "\n",
    "# Test route optimization\n",
    "sample_routes = [\n",
    "    {\"name\": \"Highway Route\", \"distance\": 45, \"traffic\": \"Light\", \"time\": 35, \"cost\": 12.50},\n",
    "    {\"name\": \"City Route\", \"distance\": 32, \"traffic\": \"Heavy\", \"time\": 55, \"cost\": 8.75}\n",
    "]\n",
    "\n",
    "print(\"\\n=== ROUTE OPTIMIZATION SIMULATION ===\")\n",
    "route_result = simulate_route_decision(sample_routes)\n",
    "\n",
    "if \"error\" not in route_result:\n",
    "    print(\"Available Routes:\")\n",
    "    for i, route in enumerate(route_result[\"routes\"], 1):\n",
    "        print(f\"  Route {i}: {route['name']} - {route['distance']}km, {route['time']}min, ${route['cost']}\")\n",
    "    \n",
    "    print(f\"\\nLLM Analysis:\\n{route_result['analysis'][:200]}...\")\n",
    "    print(f\"\\nRecommended Route: {route_result['recommended_route']}\")\n",
    "else:\n",
    "    print(f\"Error: {route_result['error']}\")\n",
    "```\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
