{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñüíª **Implement a Simple RAG Pipeline with FAISS and Hugging Face**\n",
    "\n",
    "**Time Estimate:** 60 minutes\n",
    "\n",
    "## üìã **Overview**\n",
    "\n",
    "This activity will introduce you to the concept of Retrieval-Augmented Generation (RAG) by synthesizing data retrieval with generative language models. Leveraging FAISS for efficient vector searches and Hugging Face for language model integration, you'll develop a system that enhances generative model outputs with real-time, contextually relevant information from a text corpus.\n",
    "\n",
    "- Connect real-world applications by creating a knowledge-enhanced AI system.\n",
    "- Gain hands-on experience building an application with key industry tools.\n",
    "- Understand how to merge retrieval capabilities with generative AI for improved outcomes.\n",
    "\n",
    "## üéØ **Learning Outcomes**\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "- Implement a simple RAG pipeline using FAISS and Hugging Face Transformers.\n",
    "- Generate contextually accurate and relevant outputs by integrating retrieval processes with generative models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Prepare Your Dataset [15 minutes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a small, structured text corpus as the knowledge base for retrieval.  We've provided this as the documents variable. Please feel free to add to this list or adjust this list as you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1\n",
    "documents = [\n",
    "    \"Deep learning models are solving complex problems.\",\n",
    "    \"Generative AI can create lifelike images and videos.\",\n",
    "    \"AI models need optimization to reduce biases.\",\n",
    "    \"Natural language processing enables better human-computer interaction.\",\n",
    "    \"Computer vision algorithms can detect objects in real-time.\",\n",
    "    \"Reinforcement learning helps agents learn optimal strategies.\",\n",
    "    \"Transfer learning accelerates model training on new tasks.\",\n",
    "    \"Attention mechanisms have revolutionized sequence modeling.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ **Success Checklist**\n",
    "\n",
    "- The dataset is formatted as a list of documents.\n",
    "- Documents contain diverse content for testing different queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Key Points**\n",
    "\n",
    "- Ensure the dataset is relevant and diverse to test varied prompts.\n",
    "- Quality of documents directly impacts retrieval effectiveness.\n",
    "\n",
    "‚ùó **Common Mistakes to Avoid**\n",
    "\n",
    "- Creating documents that are too similar to each other.\n",
    "- Using empty strings or very short, uninformative text.\n",
    "- Not considering the domain relevance of your documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Create Embeddings and Index [15 minutes]\n",
    "Transform documents into vector representations and build a FAISS index.\n",
    "1. Generate embeddings for your documents\n",
    "2. Create a FAISS index\n",
    "3. Add the embeddings to the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2\n",
    "# your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ **Success Checklist**\n",
    "\n",
    "- Embeddings are generated without errors.\n",
    "- FAISS index is created successfully.\n",
    "- Index contains the correct number of vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Key Points**\n",
    "\n",
    "- Use Sentence Transformers for efficient and scalable embedding generation.\n",
    "- FAISS provides fast similarity search capabilities.\n",
    "- Embedding dimension must match the model's output dimension.\n",
    "\n",
    "‚ùó **Common Mistakes to Avoid**\n",
    "\n",
    "- Using inconsistent embedding models for documents vs queries.\n",
    "- Not checking that embedding dimensions match FAISS index requirements.\n",
    "- Forgetting to convert embeddings to the correct data type for FAISS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Retrieve and Generate [30 minutes]\n",
    "Retrieve relevant information and integrate it with language model queries.\n",
    "1. Perform a query and retrieve documents\n",
    "2. Create an enhanced prompt with retrieved context\n",
    "3. Generate a response using a language model\n",
    "4. Compare the enhanced response with a baseline response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3\n",
    "# your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ **Success Checklist**\n",
    "\n",
    "- Retrieved content accurately reinforces the language model's response.\n",
    "- Responses show improved contextual relevance over baseline generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Key Points**\n",
    "\n",
    "- Combining retrieved data with generative prompts creates more grounded responses.\n",
    "- The quality of retrieval directly impacts the final generation quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùó **Common Mistakes to Avoid**\n",
    "\n",
    "- Not structuring the prompt clearly to separate context from the question.\n",
    "- Retrieving too many or too few documents for the context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ  **Next Steps**\n",
    "\n",
    "Explore further by using larger datasets or different model architectures. Understand how RAG can be applied across varied text domains to solve complex problems like sentiment analysis or domain-specific information retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíª Exemplar Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary><strong>Click HERE to see an exemplar solution</strong></summary>\n",
    "\n",
    "### Task 1 Solution\n",
    "    \n",
    "```python\n",
    "# Loading a sample dataset\n",
    "documents = [\n",
    "    \"Deep learning models are solving complex problems.\",\n",
    "    \"Generative AI can create lifelike images and videos.\",\n",
    "    \"AI models need optimization to reduce biases.\",\n",
    "    \"Natural language processing enables better human-computer interaction.\",\n",
    "    \"Computer vision algorithms can detect objects in real-time.\",\n",
    "    \"Reinforcement learning helps agents learn optimal strategies.\",\n",
    "    \"Transfer learning accelerates model training on new tasks.\",\n",
    "    \"Attention mechanisms have revolutionized sequence modeling.\"\n",
    "]\n",
    "\n",
    "print(f\"Dataset prepared with {len(documents)} documents\")\n",
    "print(\"Sample document:\", documents[0])\n",
    "```\n",
    "\n",
    "### Task 2 Solution\n",
    "    \n",
    "```python\n",
    "# Generate embeddings\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "embeddings = model.encode(documents)\n",
    "\n",
    "print(f\"Generated embeddings shape: {embeddings.shape}\")\n",
    "\n",
    "# Create FAISS index\n",
    "dim = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index.add(embeddings.astype('float32'))\n",
    "\n",
    "print(f\"FAISS index created with {index.ntotal} vectors\")\n",
    "```\n",
    "\n",
    "### Task 3 Solution\n",
    "\n",
    "```python\n",
    "# Perform a query and retrieve documents\n",
    "query = \"How do AI models optimize data?\"\n",
    "query_embedding = model.encode([query]).astype('float32')\n",
    "\n",
    "k = 2  # Number of nearest neighbors\n",
    "distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "retrieved_text = \" \".join([documents[i] for i in indices[0]])\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Retrieved documents: {retrieved_text}\")\n",
    "\n",
    "# Create enhanced prompt\n",
    "complete_prompt = f\"Info: {retrieved_text}\\\\nQ: {query}\\\\nA:\"\n",
    "\n",
    "# Integrate with LLM\n",
    "generator = pipeline('text-generation', model='distilgpt2')\n",
    "response = generator(complete_prompt, max_length=100)\n",
    "\n",
    "print(\"Enhanced Response:\", response[0]['generated_text'])\n",
    "\n",
    "# Compare with baseline (no retrieval)\n",
    "baseline_prompt = f\"Q: {query}\\\\nA:\"\n",
    "baseline_response = generator(baseline_prompt, max_length=100)\n",
    "\n",
    "print(\"\\\\nBaseline Response:\", baseline_response[0]['generated_text'])\n",
    "print(\"\\\\nComparison: The enhanced response should be more informed and contextual.\")\n",
    "```\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
