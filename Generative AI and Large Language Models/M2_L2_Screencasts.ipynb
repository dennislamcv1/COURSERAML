{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Course 4 Module 2 Lesson 2 Screencasts"
      ],
      "metadata": {
        "id": "5cS061ld2RaB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## M2L2SC1: Accessing LLMs through APIs and UIs"
      ],
      "metadata": {
        "id": "wa05u54o2Q2n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Setting Up Your Environment"
      ],
      "metadata": {
        "id": "hzajNm5X2Qwn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFdq0TBO1tmj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2cce1c1-c7ed-4aa4-a334-bbece39f67f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.82.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai transformers\n",
        "\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "# Add your API Key here\n",
        "api_key = 'your-api-key'\n",
        "\n",
        "client = OpenAI(api_key=api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Sending Prompts using APIs"
      ],
      "metadata": {
        "id": "XeD1Npf22xCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def send_prompt(prompt: str,\n",
        "                model: str = \"gpt-4o-mini\",\n",
        "                max_tokens: int = 150,\n",
        "                temperature: float = 0.7) -> str:\n",
        "    \"\"\"\n",
        "    Send a prompt to an OpenAI chat model and return the assistant’s reply.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    prompt : str\n",
        "        The user prompt or question.\n",
        "    model : str, optional\n",
        "        Chat model name (default ``\"gpt-4o-mini\"`` or any other supported model).\n",
        "    max_tokens : int, optional\n",
        "        Maximum tokens to generate (default 150).\n",
        "    temperature : float, optional\n",
        "        Sampling temperature (0.0–2.0) for creativity (default 0.7).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        The model’s response text.\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\",\n",
        "             \"content\": \"You are a helpful, concise assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens,\n",
        "        n=1  # single completion\n",
        "        # stop=None is implicit when no stop list is provided\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "prompt = \"Describe the process of photosynthesis in a simple way.\"\n",
        "\n",
        "response = send_prompt(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "acbOqvqk2wKS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "364e80c0-96e9-4017-dac4-73effaab965a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Photosynthesis is the process by which green plants, algae, and some bacteria convert sunlight into energy. Here's a simple breakdown of the process:\n",
            "\n",
            "1. **Sunlight Absorption**: Plants have a green pigment called chlorophyll, mainly found in their leaves, which captures sunlight.\n",
            "\n",
            "2. **Water and Carbon Dioxide Intake**: Plants take in water (H₂O) from the soil through their roots and carbon dioxide (CO₂) from the air through tiny openings in their leaves called stomata.\n",
            "\n",
            "3. **Energy Conversion**: Using the energy from sunlight, plants convert water and carbon dioxide into glucose (a type of sugar) and oxygen (O₂). The chemical equation for photosynthesis is:\n",
            "   \\[\n",
            "   6 \\\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## M2L2SC2: Prompt Engineering: Small Tweaks, Big Results"
      ],
      "metadata": {
        "id": "8bcNluj23Mf4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Direct Prompts"
      ],
      "metadata": {
        "id": "B0ZntMB13apr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Explain diffusion models in simple terms.\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",          # any current chat model\n",
        "    messages=[\n",
        "        {\"role\": \"system\",\n",
        "         \"content\": \"You are a clear, engaging explainer.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    max_tokens=100,\n",
        "    temperature=0.7               # optional, adjust creativity\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content.strip())"
      ],
      "metadata": {
        "id": "tG4Szl8L3Ega",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3b9235a-076a-4ec4-d811-76ced3fbd570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diffusion models are a type of machine learning technique used primarily for generating images, but they can also be applied to other types of data. Here’s a simple breakdown of how they work:\n",
            "\n",
            "1. **Starting with Noise**: Imagine you have a picture that’s completely random noise—like static on a TV. This is how diffusion models begin their process.\n",
            "\n",
            "2. **Gradual Improvement**: The model learns to gradually turn this noise into a clear image. It does this by breaking down the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: System Prompts"
      ],
      "metadata": {
        "id": "SHmoXP3L3fds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = (\n",
        "    \"Imagine you're a professor teaching about VAEs. \"\n",
        "    \"Compare them to GANs regarding their uses and limitations.\"\n",
        ")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",          # any supported chat model\n",
        "    messages=[\n",
        "        {\"role\": \"system\",\n",
        "         \"content\": \"You are a knowledgeable professor who explains concepts clearly.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    max_tokens=150,\n",
        "    temperature=0.7               # optional creativity\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "id": "pVNttFBK3iDT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6eca6e1-6843-42cf-c515-247dfcb1c235"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Certainly! Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs) are both popular models in the field of generative modeling, but they have distinct architectures, uses, and limitations.\n",
            "\n",
            "### Overview of VAEs and GANs\n",
            "\n",
            "**Variational Autoencoders (VAEs):**\n",
            "- VAEs are a type of probabilistic model that learns to encode input data into a latent space and then decode it back to the original space.\n",
            "- They consist of two main components: an encoder that maps input data to a latent space representing its distribution, and a decoder that reconstructs the data from the latent representation.\n",
            "- VAEs use a probabilistic framework, where they maximize the Evidence Lower Bound (ELBO)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Few-Shot Prompts"
      ],
      "metadata": {
        "id": "KtTZfWir3ltb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = (\n",
        "    \"Example 1: Discuss transformers in healthcare.\\n\"\n",
        "    \"Example 2: Explore AI impacts on education.\\n\"\n",
        "    \"Target: Explain diffusion models in scientific research.\"\n",
        ")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",           # any supported chat model\n",
        "    messages=[\n",
        "        {\"role\": \"system\",\n",
        "         \"content\": \"You are an expert science communicator who writes clear, engaging explanations.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    max_tokens=150,\n",
        "    temperature=0.7                # creativity (adjust as needed)\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "id": "x_Sw_LCb3oUu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0aee5f72-02c3-470a-c4c8-776d81ae43e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Diffusion Models in Scientific Research**\n",
            "\n",
            "Diffusion models are powerful analytical tools used in scientific research to describe how phenomena spread over time and space. They are particularly important in fields like epidemiology, social sciences, and ecology, where understanding the dynamics of spreading processes can lead to better predictions and interventions.\n",
            "\n",
            "### What are Diffusion Models?\n",
            "\n",
            "At their core, diffusion models help researchers understand how something—be it a disease, an innovation, or a behavior—moves through a population or environment. These models typically rely on mathematical equations that represent the rate at which the phenomenon spreads, influenced by various factors like the population's characteristics, the medium of diffusion, and external influences.\n",
            "\n",
            "### Key Concepts\n",
            "\n",
            "1. **Agents and Interactions**: In many diffusion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "46dC0Ieb3rpI"
      }
    }
  ]
}