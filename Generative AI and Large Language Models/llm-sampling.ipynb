{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8d8eaf0",
   "metadata": {},
   "source": [
    "# **Experiment with LLM Sampling Parameters**\n",
    "\n",
    "**Time Estimate:** 40 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36aa90eb",
   "metadata": {},
   "source": [
    "## **üìã Overview**\n",
    "\n",
    "In this activity, you'll explore and experiment with various sampling parameters in Large Language Models (LLMs) to understand their impact on text generation. You'll use the Hugging Face Transformers library to manipulate parameters such as temperature, top-p, and repetition penalty, allowing you to fine-tune model outputs for different applications. This skill is valuable for roles that require adapting AI model capabilities to diverse content creation needs such as content strategists and AI developers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83e1973",
   "metadata": {},
   "source": [
    "## **üéØ Learning Outcomes**\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "* Adjust temperature and top-p parameters in LLMs to influence text generation styles.  \n",
    "* Analyze changes in output to determine appropriate parameter settings for different scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2fb3e0",
   "metadata": {},
   "source": [
    "## **Task 1: Environment Setup and Initial Exploration [15 minutes]**\n",
    "\n",
    "1. Execute the code and ensure you can generate basic text outputs from the model.  \n",
    "2. Reflect: What do you observe in the default generated text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f09e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load text generation pipeline with a pre-trained model\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "# Example prompt\n",
    "prompt = \"The future of technology involves\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f6071e",
   "metadata": {},
   "source": [
    "### **‚úÖ Success Checklist**\n",
    "* Basic generation with initial model\n",
    "\n",
    "### **üí° Key Points**\n",
    "\n",
    "* Understand the default behavior of text generation models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7411e80c",
   "metadata": {},
   "source": [
    "## **Task 2: Experiment with Temperature [10 minutes]**\n",
    "\n",
    "Explore how temperature settings affect the creativity and determinism of generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355e7b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust temperature setting\n",
    "temperature_outputs = []\n",
    "for temp in [0.2, 0.5, 0.9]:\n",
    "    result = generator(prompt, max_length=50, num_return_sequences=1, temperature=temp)\n",
    "    temperature_outputs.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636c2c4a",
   "metadata": {},
   "source": [
    "### **‚úÖ Success Checklist**\n",
    "\n",
    "* Clear understanding of temperature effects  \n",
    "* Documented observations\n",
    "\n",
    "### **üí° Key Points**\n",
    "\n",
    "* Understand the impact of temperature settings through exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29555a91",
   "metadata": {},
   "source": [
    "## **Task 3: Continue Experimentation with Top-p and Repetition Penalty [15 minutes]**\n",
    "\n",
    "* Use varying top-p settings to modify token selection constraints.  \n",
    "* Implement repetition penalty adjustments to control redundancy in output sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb687ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for top-p with repetition penalty\n",
    "advanced_outputs = []\n",
    "params = {'top_k': [10, 30, 60], 'top_p': [0.9, 0.7, 0.5], 'repetition_penalty': [1.0, 2.0, 3.0]}\n",
    "for k in params['top_k']:\n",
    "    for p in params['top_p']:\n",
    "        for rp in params['repetition_penalty']:\n",
    "            result = generator(prompt, max_length=50, num_return_sequences=1, top_k=k, top_p=p, repetition_penalty=rp)\n",
    "            advanced_outputs.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4252fa19",
   "metadata": {},
   "source": [
    "### **‚úÖ Success Checklist**\n",
    "\n",
    "* Completed multiple experiments with different parameters  \n",
    "* In-depth analysis documented\n",
    "\n",
    "### **üí° Key Points**\n",
    "\n",
    "* Understand varying top-p and repitition penalty through experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2142f783",
   "metadata": {},
   "source": [
    "## **‚ùó Common Mistakes to Avoid**\n",
    "\n",
    "* Overlook adjusting too many parameters simultaneously: It may complicate understanding.  \n",
    "* Focusing on only one type of output: Explore various scenarios for balanced insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51727cc",
   "metadata": {},
   "source": [
    "## **üöÄ Next Steps**\n",
    "\n",
    "Advance your skills by exploring how these parameters are used in real-world AI applications or by tuning parameters for industry-specific tasks, enhancing both creative and procedural text generation capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114f7336",
   "metadata": {},
   "source": [
    "## **üìãExemplar Solution**\n",
    "<details>\n",
    "<summary><strong>\n",
    "Click HERE to see an exemplar solution\n",
    "</summary></strong>\n",
    "\n",
    "### **Task 2 Solution**\n",
    "\n",
    "Reflect on the varied creative outputs based on temperature:\n",
    "\n",
    "* **Temperature 0.2**: Consistent and predictable, ideal for factual presentations.\n",
    "\n",
    "### **Task 3 Solution**\n",
    "\n",
    "* **Top-p 0.9**: Reduced choices ensure more focused content, great for clarity-driven tasks.\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
