{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d9f8632",
   "metadata": {},
   "source": [
    "# üë©‚Äçüíª Reducing Dimensionality with PCA: From 64 Features to 2\n",
    "\n",
    "## üìã Overview\n",
    "In this lab, you will have the opportunity to gain hands-on experience implementing PCA to effectively reduce the dimensionality of data using the Digits dataset. By the end of this activity, you will understand how PCA selects the most informative features, reducing complex datasets into essential dimensions while preserving their core structure.\n",
    "\n",
    "## üéØ Learning Outcomes\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "- ‚úÖ Apply Principal Component Analysis (PCA) to reduce the dimensions of a dataset\n",
    "- ‚úÖ Analyze the explained variance to evaluate the effectiveness of PCA\n",
    "- ‚úÖ Visualize the results of PCA to interpret data clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ae1a62",
   "metadata": {},
   "source": [
    "## Task 1: Data Import and Preparation\n",
    "\n",
    "**Context:** Proper data preparation is essential before applying PCA.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Standardize the dataset to ensure that all features contribute equally to PCA, eliminating biases due to different scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9f2923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the Digits dataset\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Data Prepartion\n",
    "# your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8156d54",
   "metadata": {},
   "source": [
    "üí° **Tip:** Use `load_digits()` to load the dataset, and `StandardScaler` to standardize the data.\n",
    "\n",
    "‚öôÔ∏è **Test Your Work:**\n",
    "- Display the first 5 rows of the standardized dataset.\n",
    "\n",
    "**Expected output:** Standardized feature values for the first 5 samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd053d1",
   "metadata": {},
   "source": [
    "## Task 2: Implement PCA\n",
    "\n",
    "**Context:** Applying PCA reduces the dimensionality of the dataset while retaining the most significant features.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Apply PCA to transform the original dataset into two principal components.\n",
    "2. Analyze the explained variance to evaluate how well these two components represent the overall variance in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb99d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Implement PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d2a2ca",
   "metadata": {},
   "source": [
    "üí° **Tip:** Use `PCA` from `sklearn.decomposition` with `n_components=2`.\n",
    "\n",
    "‚öôÔ∏è **Test Your Work:**\n",
    "- Print the explained variance for the two principal components.\n",
    "\n",
    "**Expected output:** Percentage of variance explained by each of the two components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96483472",
   "metadata": {},
   "source": [
    "## Task 3: Visualize PCA Results\n",
    "\n",
    "**Context:** Visualization helps in interpreting the results of PCA and understanding data clustering.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Plot the reduced dimensions and visualize the clusters of digits.\n",
    "2. Interpret the visualization to understand how different digits are grouped based on the principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc2cdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Visualize PCA Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ab0c46",
   "metadata": {},
   "source": [
    "üí° **Tip:** Use `matplotlib` for plotting with appropriate labels and title.\n",
    "\n",
    "‚öôÔ∏è **Test Your Work:**\n",
    "- Display a scatter plot of the two principal components with color coding for different digits.\n",
    "\n",
    "**Expected output:** A visual representation showing clusters of different digits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76366cd1",
   "metadata": {},
   "source": [
    "### ‚úÖ Success Checklist\n",
    "\n",
    "- Successfully loaded and standardized the dataset\n",
    "- Applied PCA to reduce the dataset to two principal components\n",
    "- Analyzed the explained variance of the principal components\n",
    "- Visualized the PCA results to interpret data clustering\n",
    "- Reflect on the PCA process and its applications\n",
    "\n",
    "### üîç Common Issues & Solutions\n",
    "\n",
    "**Problem:** Dataset not loading.  \n",
    "**Solution:** Ensure the correct function `load_digits()` is used.\n",
    "\n",
    "**Problem:** PCA implementation errors.  \n",
    "**Solution:** Verify the PCA setup with the correct number of components.\n",
    "\n",
    "**Problem:** Visualization issues.  \n",
    "**Solution:** Ensure that `plt.scatter()` is correctly configured with labels and color coding.\n",
    "\n",
    "### üîë Key Points\n",
    "\n",
    "- PCA is a powerful technique for dimensionality reduction that retains the most informative features.\n",
    "- Proper data standardization is crucial before applying PCA.\n",
    "- Visualizing PCA results helps in understanding and interpreting data clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f77f9aa",
   "metadata": {},
   "source": [
    "## üíª Exempler Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7a4ab3",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary><strong>Click HERE to see an exemplar solution</strong></summary>    \n",
    "\n",
    "```python\n",
    "# Required Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the Digits dataset\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_std)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='Spectral', alpha=0.7, edgecolors='w')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('PCA on Digits Dataset')\n",
    "plt.colorbar(scatter)\n",
    "plt.show()\n",
    "\n",
    "# Explained variance\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(f\"Explained Variance: {explained_variance}\")\n",
    "print(f\"Total Explained Variance by {pca.n_components} components: {np.sum(explained_variance):0.4f}\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
