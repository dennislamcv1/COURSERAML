{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd6ef8f9",
   "metadata": {},
   "source": [
    "# üë©‚Äçüíª Bagging in Action: Predicting Customer Churn with Random Forest\n",
    "\n",
    "## üìã Overview\n",
    "In this lab, you'll implement bagging techniques using a Random Forest to predict customer churn. Predicting customer churn is critical for businesses as it allows them to proactively address issues and improve customer retention strategies. By leveraging the Telco Customer Churn dataset, you will build and evaluate a Random Forest model to make these predictions.\n",
    "\n",
    "## üéØ Learning Outcomes\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "- ‚úÖ Perform data preprocessing and exploratory data analysis (EDA) on a real dataset.  \n",
    "- ‚úÖ Implement and train a Random Forest model to predict customer churn.  \n",
    "- ‚úÖ Evaluate the model's performance using relevant metrics.  \n",
    "- ‚úÖ Analyze feature importance from the trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cab79d",
   "metadata": {},
   "source": [
    "## üìÇ Task 1:  Data Preparation\n",
    "\n",
    "**Context:** Before building a model, it is essential to understand and preprocess your data.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. **Load the Data:**  \n",
    "     \n",
    "   - Load the Telco Customer Churn dataset using `pandas`.  \n",
    "   - Display the first few rows to understand the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "710b0bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load Data\n",
    "df = pd.read_csv('Telco-Customer-Churn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df0dac7",
   "metadata": {},
   "source": [
    "2. **Explore the Data:**  \n",
    "     \n",
    "   - Use `.info()`, `.describe()`, and visualize data distributions to uncover insights.  \n",
    "   - Identify and handle missing values if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8098aebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712af344",
   "metadata": {},
   "source": [
    "3. **Preprocess the Data:**  \n",
    "     \n",
    "   - Convert categorical variables to numerical using `LabelEncoder` or `pd.get_dummies()`.  \n",
    "   - Separate features and target variable (Churn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ea5438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b8f97f",
   "metadata": {},
   "source": [
    "üí° **Tip:** Look for columns with many unique values during categorical encoding.\n",
    "\n",
    "‚öôÔ∏è **Test Your Work:**\n",
    "- Ensure no missing values in the final DataFrame.  \n",
    "- Verify all categorical variables are encoded correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789d4ab0",
   "metadata": {},
   "source": [
    "## üîç Task 2: Splitting the Data\n",
    "\n",
    "**Context:** Splitting the dataset ensures that your model is trained and tested on different data, promoting fairness and performance evaluation.\n",
    "\n",
    "**Steps:**\n",
    "   - Use `train_test_split` to divide the dataset into training and testing sets (80%-20%).\n",
    "\n",
    "üí° **Tip:** Keep a random state for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffbe8239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f8812d",
   "metadata": {},
   "source": [
    "‚öôÔ∏è **Test Your Work:**\n",
    "\n",
    "- Confirm the shapes of the training and testing sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0e0b9d",
   "metadata": {},
   "source": [
    "## üßπ Task 3: Model Building and Training\n",
    "\n",
    "**Context:** Building and training the model is the core step where the Random Forest algorithm is applied.\n",
    "\n",
    "**Steps:**\n",
    "     \n",
    "   - Create a `RandomForestClassifier` with 100 trees.\n",
    "     \n",
    "   - Fit the classifier on the training data.\n",
    "     \n",
    "   - Experiment with `n_estimators`, `max_depth`, and `max_features` to optimize performance.\n",
    "\n",
    "üí° **Tip:** Use GridSearchCV to automate hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1054d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Building and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194bea00",
   "metadata": {},
   "source": [
    "‚öôÔ∏è **Test Your Work:**\n",
    "- Ensure your model trains without errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fe0806",
   "metadata": {},
   "source": [
    "## üß† Task 4: Feature Selection\n",
    "**Context:** Evaluating the model is crucial to understand its real-world performance.\n",
    "\n",
    "**Steps:**\n",
    "     \n",
    "   - Use your trained model to predict on the test set.\n",
    "     \n",
    "   - Use `classification_report` to assess metrics like accuracy, precision, recall, and F1 score.\n",
    "\n",
    "üí° **Tip:** Analyze the confusion matrix for more detailed insight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615a4571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc4477f",
   "metadata": {},
   "source": [
    "‚öôÔ∏è **Test Your Work:**\n",
    "- Validate the classification report output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8825c71a",
   "metadata": {},
   "source": [
    "## üß™ Task 5: Feature Importance Analysis\n",
    "**Context:** Understanding which features matter more helps in model interpretability and further feature engineering.\n",
    "\n",
    "**Steps:**\n",
    "     \n",
    "   - Retrieve and print feature importances from the Random Forest model.\n",
    "     \n",
    "   - Identify the top contributing features and interpret their impact.\n",
    "\n",
    "üí° **Tip:** Plot a bar chart for visual representation of feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033a616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a274ad",
   "metadata": {},
   "source": [
    "‚öôÔ∏è **Test Your Work:**\n",
    "- Ensure you get a clear ranking of features by their importance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208959a7",
   "metadata": {},
   "source": [
    "### ‚úÖ Success Checklist\n",
    "\n",
    "- Data is preprocessed without errors.  \n",
    "- Data is split into training and testing sets correctly.  \n",
    "- Random Forest model is instantiated and trained successfully.  \n",
    "- Model evaluation metrics are correctly calculated and interpreted.  \n",
    "- Feature importances are analyzed and visualized.\n",
    "\n",
    "### üîç Common Issues & Solutions\n",
    "\n",
    "**Problem:** Data leakage during preprocessing.   \n",
    "**Solution:** Ensure splitting data before transformations or using pipelines.  \n",
    "\n",
    "**Problem:** Overfitting the model.  \n",
    "**Solution:** Tune `max_depth`, use cross-validation, and analyze if the model performs consistently on test data.  \n",
    "\n",
    "### üîë Key Points\n",
    "\n",
    "- Bagging with Random Forests helps improve model stability and reduce overfitting.  \n",
    "- Data preprocessing and proper splitting are foundational for model performance.  \n",
    "- Evaluating with multiple metrics provides a comprehensive view of model capabilities.  \n",
    "- Feature importance analysis aids in model interpretability and potential feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d229aa0",
   "metadata": {},
   "source": [
    "## Exemplar Solution\n",
    "\n",
    "After completing this activity (or if you get stuck!), take a moment to review the exemplar solution. This sample solution can offer insights into different techniques and approaches. \n",
    "\n",
    "Reflect on what you can learn from the exemplar solution to improve your coding skills.\n",
    "\n",
    "Remember, multiple solutions can exist for some problems; the goal is to learn and grow as a programmer by exploring various approaches.\n",
    "\n",
    "Use the exemplar solution as a learning tool to enhance your understanding and refine your approach to coding challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746653c0",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary><strong>Click HERE to see an exemplar solution</strong></summary>    \n",
    "\n",
    "```python\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load Data\n",
    "df = pd.read_csv('Telco-Customer-Churn.csv')\n",
    "\n",
    "# Data Preprocessing\n",
    "# Example: Encode categorical columns (assuming non-numeric columns need encoding)\n",
    "label_encoder = LabelEncoder()\n",
    "for column in df.select_dtypes(include=['object']).columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column])\n",
    "\n",
    "# Split the data\n",
    "X = df.drop('Churn', axis=1)  # Features\n",
    "y = df['Churn']  # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the random forest model\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature Importance\n",
    "importances = rf_clf.feature_importances_\n",
    "feature_importances = pd.Series(importances, index=X.columns).sort_values(ascending=False)\n",
    "print(feature_importances.head(10))\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
