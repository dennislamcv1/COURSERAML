{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84424414",
   "metadata": {},
   "source": [
    "# üë©‚Äçüíª AutoML vs. Manual Modeling: Which One Wins?\n",
    "\n",
    "Time Estimate: 60 minutes\n",
    "\n",
    "## üìã Overview\n",
    "\n",
    "In this engaging lab activity, you'll immerse yourself in the exciting world of machine learning by directly comparing AutoML solutions with traditional manual modeling. This exercise gives you firsthand experience, allowing you to weigh the strengths and weaknesses of each approach when solving a real-world problem. By the end, you'll gain critical insights into when to choose one method over the other based on data, context, and objectives.\n",
    "\n",
    "## üéØ Learning Outcomes\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "- Implement manual modeling techniques using scikit-learn  \n",
    "- Perform hyperparameter tuning using GridSearchCV or RandomizedSearchCV  \n",
    "- Set up and run AutoML experiments using auto-sklearn or PyCaret  \n",
    "- Compare the effectiveness of AutoML and manual modeling approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82a6017",
   "metadata": {},
   "source": [
    "## üñ•Ô∏è Tasks\n",
    "\n",
    "### Task 1: Dataset Preprocessing\n",
    "\n",
    "**Context:** Proper dataset selection and preprocessing ensures the data is clean and ready for modeling.  \n",
    "**Steps:**\n",
    "\n",
    "1. Ensure the dataset is preprocessed: handle missing data, normalize features as needed, and split into training and testing sets.\n",
    "\n",
    "**üí° Tip:** Use `train_test_split` from `sklearn.model_selection` for data splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375d36f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import autosklearn.classification\n",
    "\n",
    "# Load data\n",
    "iris = load_iris()\n",
    "\n",
    "# Task 1: Dataset Preprocessing\n",
    "# ... your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba694486",
   "metadata": {},
   "source": [
    "**‚öôÔ∏è Test Your Work:**  \n",
    "The dataset should show the features and corresponding labels, demonstrating the preprocessing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e044038c",
   "metadata": {},
   "source": [
    "### Task 2: Manual Modeling Approach\n",
    "\n",
    "**Context:** Manual modeling involves constructing pipelines, choosing algorithms, and performing hyperparameter tuning.  \n",
    "**Steps:**\n",
    "\n",
    "1. Construct a pipeline manually using scikit-learn. Choose a few algorithms such as logistic regression, decision trees, or SVM for initial model construction.  \n",
    "2. Perform hyperparameter tuning using `GridSearchCV` or `RandomizedSearchCV` to optimize model performance.  \n",
    "3. Record the results, including accuracy, precision, recall, and computational time.\n",
    "\n",
    "**üí° Tip:** Use `GridSearchCV` for systematic hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0086ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Manual Modeling Approach\n",
    "# ... your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d840e001",
   "metadata": {},
   "source": [
    "**‚öôÔ∏è Test Your Work:**  \n",
    "Plots should clearly show the comparison of actual vs. predicted values for the manually tuned models.  \n",
    "Legends should correctly identify each model and data series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40562635",
   "metadata": {},
   "source": [
    "### Task 3: AutoML Approach using auto-sklearn\n",
    "\n",
    "**Context:** AutoML tools automate feature engineering, model selection, and hyperparameter tuning.  \n",
    "**Steps:**\n",
    "\n",
    "1. Set up and run an AutoML experiment with your chosen dataset using auto-sklearn.\n",
    "2. Compare best models based on their capability using similar metrics (accuracy, precision, recall) while noting time efficiency.\n",
    "\n",
    "**üí° Tip:** Use `AutoSklearnClassifier` from `autosklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c34255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: AutoML Approach using auto-sklearn\n",
    "# ... your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a05c0f5",
   "metadata": {},
   "source": [
    "**‚öôÔ∏è Test Your Work:**  \n",
    "Plots should clearly show the comparison of actual vs. predicted values for the AutoML models.  \n",
    "Legends should correctly identify each AutoML model and data series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e615c512",
   "metadata": {},
   "source": [
    "\n",
    "### Task 4: Compare and Analyze Results\n",
    "\n",
    "**Context:** Comparing results helps evaluate the strengths and weaknesses of AutoML vs. manual modeling approaches.  \n",
    "**Steps:**\n",
    "\n",
    "1. Compare the results from both the manual and AutoML approaches. Identify differences in performance, time efficiency, resource usage, and overall experience.  \n",
    "2. Consider the variety of models tried, accuracy trade-offs, and ease of implementation.\n",
    "\n",
    "**üí° Tip:** Use visualizations or statistical summaries to aid comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d2aadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: Compare and Analyze Results\n",
    "# ... your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c811de",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**‚öôÔ∏è Test Your Work:**  \n",
    "Plots should clearly illustrate the performance comparison between manual and AutoML approaches.\n",
    "\n",
    "Legends should correctly identify each approach and the corresponding performance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34d5f40",
   "metadata": {},
   "source": [
    "## ‚úÖ Success Checklist\n",
    "\n",
    "- Successfully selected and preprocessed the dataset  \n",
    "- Implemented and tuned manual modeling techniques  \n",
    "- Set up and run AutoML experiments  \n",
    "- Compared and analyzed results from both approaches  \n",
    "- Provided reflections and recommendations based on findings\n",
    "\n",
    "## üîç Common Issues & Solutions\n",
    "\n",
    "**Problem:** Dataset not loading correctly.  \n",
    "**Solution:** Verify the data source and ensure proper loading using `pandas`.\n",
    "\n",
    "**Problem:** Hyperparameter tuning errors.  \n",
    "**Solution:** Check the parameter grid and ensure compatibility with the chosen algorithm.\n",
    "\n",
    "**Problem:** AutoML tools not functioning.  \n",
    "**Solution:** Ensure correct setup and usage of auto-sklearn or PyCaret.\n",
    "\n",
    "## üîë Key Points\n",
    "\n",
    "- Manual modeling allows precise control over model construction and tuning.  \n",
    "- AutoML tools simplify the process by automating feature engineering, model selection, and hyperparameter tuning.  \n",
    "- Comparing results helps understand the strengths, weaknesses, and suitable applications of each approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a255622",
   "metadata": {},
   "source": [
    "## Exemplar Solution\n",
    "\n",
    "After completing this activity (or if you get stuck!), take a moment to review the exemplar solution. This sample solution can offer insights into different techniques and approaches.\n",
    "\n",
    "Reflect on what you can learn from the exemplar solution to improve your coding skills.\n",
    "\n",
    "Remember, multiple solutions can exist for some problems; the goal is to learn and grow as a programmer by exploring various approaches.\n",
    "\n",
    "Use the exemplar solution as a learning tool to enhance your understanding and refine your approach to coding challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1c88db",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary><strong>Click HERE to see an exemplar solution</strong></summary>  \n",
    "\n",
    "## üíª Reference Solution\n",
    "\n",
    "```py\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import autosklearn.classification\n",
    "\n",
    "# Load and preprocess dataset\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Manual Model - Logistic Regression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "log_pred = log_reg.predict(X_test)\n",
    "log_acc = accuracy_score(y_test, log_pred)\n",
    "\n",
    "# Example manual hyperparameter tuning for Decision Tree\n",
    "param_grid = {'max_depth': [3, 5, 7, None]}\n",
    "tree = GridSearchCV(DecisionTreeClassifier(), param_grid, scoring='accuracy')\n",
    "tree.fit(X_train, y_train)\n",
    "tree_pred = tree.best_estimator_.predict(X_test)\n",
    "tree_acc = accuracy_score(y_test, tree_pred)\n",
    "\n",
    "# AutoML Model - Auto-sklearn\n",
    "automl = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task=60, per_run_time_limit=30, memory_limit=6000)\n",
    "automl.fit(X_train, y_train)\n",
    "automl_pred = automl.predict(X_test)\n",
    "automl_acc = accuracy_score(y_test, automl_pred)\n",
    "\n",
    "print(f\"Manual Logistic Regression Accuracy: {log_acc}\")\n",
    "print(f\"Best Decision Tree Accuracy: {tree_acc}\")\n",
    "print(f\"AutoML Best Model Accuracy: {automl_acc}\")\n",
    "```\n",
    "</details>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
