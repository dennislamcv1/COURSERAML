{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b75e216",
   "metadata": {},
   "source": [
    "# üë©‚Äçüíª Simulate Your First RL Environment with an Agent in GridWorld\n",
    "\n",
    "## üìã Overview\n",
    "This lab invites you to delve into the core mechanics of Reinforcement Learning by simulating a simple RL environment: GridWorld. You will implement a fundamental RL loop, providing you with essential insights into how agents learn and adapt within a defined environment. By completing this activity, you'll understand the interactions between agents, actions, and rewards‚Äîkey components that determine the success of an RL system.\n",
    "\n",
    "## üéØ Learning Outcomes\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "- ‚úÖ Set up and simulate a basic RL environment using GridWorld\n",
    "- ‚úÖ Define agent actions and rewards in the environment\n",
    "- ‚úÖ Implement and evaluate a simple random policy\n",
    "- ‚úÖ Analyze agent performance and explore ways to improve policies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7bb636",
   "metadata": {},
   "source": [
    "## Task 1: Set Up the GridWorld Environment\n",
    "\n",
    "**Context:** Setting up the GridWorld environment with start and goal states is the first step.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Create a GridWorld environment with defined start and goal states.\n",
    "2. Use a simple grid to model the space your agent will navigate, initially starting at one corner while trying to reach a designated goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ef6bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Set Up the GridWorld Environment\n",
    "import numpy as np\n",
    "\n",
    "# Your code here.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44792076",
   "metadata": {},
   "source": [
    "üí° **Tip:** Use a grid size of 5x5 for simplicity.\n",
    "\n",
    "‚öôÔ∏è **Test Your Work:**\n",
    "- Print the initial state of the environment.\n",
    "\n",
    "**Expected output:** The starting position of the agent on the grid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206208ff",
   "metadata": {},
   "source": [
    "## Task 2: Define Agent Actions and Rewards\n",
    "\n",
    "**Context:** Implementing actions and rewards allows the agent to interact meaningfully with the environment.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Implement the possible actions for the agent (e.g., moving right, down).\n",
    "2. Incorporate a reward system where the agent receives positive feedback upon reaching the goal and a small penalty for each move that does not reach the goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bd587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Define Agent Actions and Rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a97e66",
   "metadata": {},
   "source": [
    "üí° **Tip:** Define small penalties to encourage strategic pathfinding.\n",
    "\n",
    "‚öôÔ∏è **Test Your Work:**\n",
    "- Print the state and reward after a few actions.\n",
    "\n",
    "**Expected output:** The new state and reward based on the agent's actions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc716a9",
   "metadata": {},
   "source": [
    "## Task 3: Create a Random Policy for Exploration\n",
    "\n",
    "**Context:** Developing a random policy enables the agent to explore the environment.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Develop a basic policy that allows the agent to make decisions at random from the available actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc32d6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Create a Random Policy for Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da82f1c1",
   "metadata": {},
   "source": [
    "üí° **Tip:** Use `np.random.choice` to select random actions.\n",
    "\n",
    "‚öôÔ∏è **Test Your Work:**\n",
    "- Print the actions selected by the random policy.\n",
    "\n",
    "**Expected output:** A series of randomly selected actions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffca082",
   "metadata": {},
   "source": [
    "## Task 4: Implement the Reinforcement Learning Loop\n",
    "\n",
    "**Context:** The RL loop simulates the agent's interaction with the environment over multiple episodes.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Set up the RL loop where the agent continually interacts with the environment, executing actions, updating its state, and receiving rewards.\n",
    "2. Simulate multiple episodes where the agent endeavors to reach the goal, adjusting its actions over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492c77d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: Implement the Reinforcement Learning Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6646a30",
   "metadata": {},
   "source": [
    "üí° **Tip:** Use a loop to simulate multiple episodes and track the total rewards and steps taken.\n",
    "\n",
    "‚öôÔ∏è **Test Your Work:**\n",
    "- Print the total rewards and steps taken for each episode.\n",
    "\n",
    "**Expected output:** The performance metrics for each episode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a11a93",
   "metadata": {},
   "source": [
    "### ‚úÖ Success Checklist\n",
    "\n",
    "- Successfully set up the GridWorld environment with defined start and goal states\n",
    "- Implemented agent actions and rewards\n",
    "- Developed and evaluated a random policy\n",
    "- Simulated the RL loop and analyzed agent performance\n",
    "- Explored ways to improve the agent's policy\n",
    "\n",
    "### üîç Common Issues & Solutions\n",
    "\n",
    "**Problem:** Agent actions not updating the state correctly.   \n",
    "**Solution:** Ensure the actions are correctly defined and update the state as intended.\n",
    "\n",
    "**Problem:** Rewards not being calculated properly.   \n",
    "**Solution:** Verify the reward logic and ensure it's being applied correctly for each action.\n",
    "\n",
    "**Problem:** Agent not reaching the goal.   \n",
    "**Solution:** Check the random policy and try increasing the number of episodes for more exploration.\n",
    "\n",
    "### üîë Key Points\n",
    "\n",
    "- Setting up and simulating an RL environment helps understand the core mechanics of reinforcement learning.\n",
    "- Defining clear actions and rewards is crucial for meaningful agent interactions.\n",
    "- Analyzing performance and exploring improvements are key steps in optimizing RL models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526fda4e",
   "metadata": {},
   "source": [
    "## üíª Exemplar Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba01f855",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary><strong>Click HERE to see an exemplar solution</strong></summary>    \n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "class GridWorld:\n",
    "    def __init__(self, size=5, start=(0, 0), goal=(4, 4)):\n",
    "        self.size = size\n",
    "        self.state = start\n",
    "        self.goal = goal\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = (0, 0)\n",
    "        return self.state\n",
    "\n",
    "    def is_goal_reached(self):\n",
    "        return self.state == self.goal\n",
    "\n",
    "    def step(self, action):\n",
    "        x, y = self.state\n",
    "        if action == \"right\" and x < self.size - 1:\n",
    "            x += 1\n",
    "        elif action == \"down\" and y < self.size - 1:\n",
    "            y += 1\n",
    "        self.state = (x, y)\n",
    "        reward = 1 if self.is_goal_reached() else -0.04  # Small penalty for each move\n",
    "        return self.state, reward\n",
    "\n",
    "# Define agent's possible actions\n",
    "actions = [\"right\", \"down\"]\n",
    "\n",
    "def random_policy():\n",
    "    return np.random.choice(actions)\n",
    "\n",
    "# Simulation of the Reinforcement Learning Loop\n",
    "env = GridWorld()\n",
    "num_episodes = 10\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    step_count = 0\n",
    "    while not env.is_goal_reached():\n",
    "        action = random_policy()  # Select action based on random policy\n",
    "        state, reward = env.step(action)\n",
    "        total_reward += reward\n",
    "        step_count += 1\n",
    "    print(f\"Episode {episode + 1}: Total Reward: {total_reward:.2f}, Steps Taken: {step_count}\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
